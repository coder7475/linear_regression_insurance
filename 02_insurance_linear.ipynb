{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coder7475/linear_regression_insurance/blob/main/02_insurance_linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "ZDqysqUcC-lP"
      },
      "source": [
        "# Insurance cost prediction using linear regression\n",
        "\n",
        "Make a submisson here: https://jovian.ai/learn/deep-learning-with-pytorch-zero-to-gans/assignment/assignment-2-train-your-first-model\n",
        "\n",
        "In this assignment we're going to use information like a person's age, sex, BMI, no. of children and smoking habit to predict the price of yearly medical bills. This kind of model is useful for insurance companies to determine the yearly insurance premium for a person. The dataset for this problem is taken from [Kaggle](https://www.kaggle.com/mirichoi0218/insurance).\n",
        "\n",
        "\n",
        "We will create a model with the following steps:\n",
        "1. Download and explore the dataset\n",
        "2. Prepare the dataset for training\n",
        "3. Create a linear regression model\n",
        "4. Train the model to fit the data\n",
        "5. Make predictions using the trained model\n",
        "\n",
        "\n",
        "This assignment builds upon the concepts from the first 2 lessons. It will help to review these Jupyter notebooks:\n",
        "- PyTorch basics: https://jovian.ai/aakashns/01-pytorch-basics\n",
        "- Linear Regression: https://jovian.ai/aakashns/02-linear-regression\n",
        "- Logistic Regression: https://jovian.ai/aakashns/03-logistic-regression\n",
        "- Linear regression (minimal): https://jovian.ai/aakashns/housing-linear-minimal\n",
        "- Logistic regression (minimal): https://jovian.ai/aakashns/mnist-logistic-minimal\n",
        "\n",
        "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end . In some cases, you'll be required to choose some hyperparameters (learning rate, batch size etc.). Try to experiment with the hypeparameters to get the lowest loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-puXlLzeC-lZ",
        "outputId": "afb485eb-cce3-4c8e-acc2-73858fbd08ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jovian in /usr/local/lib/python3.9/dist-packages (0.2.47)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from jovian) (8.1.3)\n",
            "Requirement already satisfied: uuid in /usr/local/lib/python3.9/dist-packages (from jovian) (1.30)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from jovian) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from jovian) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->jovian) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->jovian) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->jovian) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->jovian) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "# Uncomment and run the appropriate command for your operating system, if required\n",
        "\n",
        "# Linux / Binder\n",
        "# !pip install numpy matplotlib pandas torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# Windows\n",
        "# !pip install numpy matplotlib pandas torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# MacOS\n",
        "# !pip install numpy matplotlib pandas torch torchvision torchaudio\n",
        "!pip install jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ABkTaVYnC-lf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import jovian\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "6lMg1_CiC-lk"
      },
      "outputs": [],
      "source": [
        "project_name='02-insurance-linear-regression' # will be used by jovian.commit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWtmSUOvC-lo"
      },
      "source": [
        "## Step 1: Download and explore the data\n",
        "\n",
        "Let us begin by downloading the data. We'll use the `download_url` function from PyTorch to get the data as a CSV (comma-separated values) file. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htSk9UOrC-lp",
        "outputId": "639250d4-6b80-4e03-9c9c-b5db17adccad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./insurance.csv\n"
          ]
        }
      ],
      "source": [
        "DATASET_URL = \"https://gist.github.com/BirajCoder/5f068dfe759c1ea6bdfce9535acdb72d/raw/c84d84e3c80f93be67f6c069cbdc0195ec36acbd/insurance.csv\"\n",
        "DATA_FILENAME = \"insurance.csv\"\n",
        "download_url(DATASET_URL, '.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfPL6CqyC-ls"
      },
      "source": [
        "To load the dataset into memory, we'll use the `read_csv` function from the `pandas` library. The data will be loaded as a Pandas dataframe. See this short tutorial to learn more: https://data36.com/pandas-tutorial-1-basics-reading-data-files-dataframes-data-selection/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gQGoJlDeC-lu",
        "outputId": "dccc9292-c28e-4cc7-a0dd-a7074e4a79d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9825347-3824-48c6-95bc-0c9e63fa0887\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9825347-3824-48c6-95bc-0c9e63fa0887')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9825347-3824-48c6-95bc-0c9e63fa0887 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9825347-3824-48c6-95bc-0c9e63fa0887');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "dataframe_raw = pd.read_csv(DATA_FILENAME)\n",
        "dataframe_raw.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgYOrJMaC-lx"
      },
      "source": [
        "We're going to do a slight customization of the data, so that you every participant receives a slightly different version of the dataset. Fill in your name below as a string (enter at least 5 characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "d1Tc4ZStC-lz"
      },
      "outputs": [],
      "source": [
        "your_name = 'Robiul' # at least 5 characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHnuh3SoC-l1"
      },
      "source": [
        "The `customize_dataset` function will customize the dataset slightly using your name as a source of random numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "qidz_xVPC-l3"
      },
      "outputs": [],
      "source": [
        "def customize_dataset(dataframe_raw, rand_str):\n",
        "    dataframe = dataframe_raw.copy(deep=True)\n",
        "    # drop some rows\n",
        "    dataframe = dataframe.sample(int(0.95*len(dataframe)), random_state=int(ord(rand_str[0])))\n",
        "    # scale input\n",
        "    dataframe.bmi = dataframe.bmi * ord(rand_str[1])/100.\n",
        "    # scale target\n",
        "    dataframe.charges = dataframe.charges * ord(rand_str[2])/100.\n",
        "    # drop column\n",
        "    if ord(rand_str[3]) % 2 == 1:\n",
        "        dataframe = dataframe.drop(['region'], axis=1)\n",
        "    return dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nQVVUROqC-l4",
        "outputId": "884157ee-3502-45ce-ba15-65969fbfb256"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      age     sex       bmi  children smoker       charges\n",
              "457    57  female  33.84945         0     no  11603.959549\n",
              "1050   44  female  41.02005         1     no   7862.672741\n",
              "56     58  female  35.32575         2     no  13335.221375\n",
              "311    19  female  27.41700         0     no   1702.628480\n",
              "1288   20    male  43.73400         2    yes  37577.674680"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a591d19-bd81-4aa5-a3b8-c3abe20946f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>57</td>\n",
              "      <td>female</td>\n",
              "      <td>33.84945</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>11603.959549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>44</td>\n",
              "      <td>female</td>\n",
              "      <td>41.02005</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>7862.672741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>58</td>\n",
              "      <td>female</td>\n",
              "      <td>35.32575</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>13335.221375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.41700</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>1702.628480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1288</th>\n",
              "      <td>20</td>\n",
              "      <td>male</td>\n",
              "      <td>43.73400</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>37577.674680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a591d19-bd81-4aa5-a3b8-c3abe20946f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a591d19-bd81-4aa5-a3b8-c3abe20946f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a591d19-bd81-4aa5-a3b8-c3abe20946f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "dataframe = customize_dataset(dataframe_raw, your_name)\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE4k5KF2C-l7"
      },
      "source": [
        "Let us answer some basic questions about the dataset. \n",
        "\n",
        "\n",
        "**Q1: How many rows does the dataset have?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SiKk-d3C-l9",
        "outputId": "68fb13d3-fc87-4abf-ed62-db9106fc0dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1271\n"
          ]
        }
      ],
      "source": [
        "#num_rows = len(dataframe.index);\n",
        "num_rows = dataframe.shape[0]\n",
        "print(num_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2486ApcEC-mA"
      },
      "source": [
        "**Q2: How many columns doe the dataset have**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8G4aGJ0C-mB",
        "outputId": "dcab09c7-a3a4-4ed3-9454-2b02ce7d370a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "num_cols = dataframe.shape[1]\n",
        "print(num_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycr7F3SjC-mE"
      },
      "source": [
        "**Q3: What are the column titles of the input variables?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVMgWZPDC-mF",
        "outputId": "e8926fda-f0b8-4e5e-c2a5-267332b20075"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'sex', 'bmi', 'children', 'smoker']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "input_cols = dataframe.columns[:-1].to_list()\n",
        "input_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaAjeF7vC-mG"
      },
      "source": [
        "**Q4: Which of the input columns are non-numeric or categorial variables ?**\n",
        "\n",
        "Hint: `sex` is one of them. List the columns that are not numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrBA7UELC-mG",
        "outputId": "df399986-25a1-48b3-ea88-237a05830cab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sex', 'smoker']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "categorical_cols = dataframe.select_dtypes(exclude=['number']).columns.to_list()\n",
        "categorical_cols"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2lgep78C-mG"
      },
      "source": [
        "**Q5: What are the column titles of output/target variable(s)?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Uvb8lSPBC-mH"
      },
      "outputs": [],
      "source": [
        "output_cols = ['charges']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z82nzVghC-mI"
      },
      "source": [
        "**Q: (Optional) What is the minimum, maximum and average value of the `charges` column? Can you show the distribution of values in a graph?**\n",
        "Use this data visualization cheatsheet for referece: https://jovian.ai/aakashns/dataviz-cheatsheet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "vUiPNfZsC-mI",
        "outputId": "02a4d37c-c31d-44f6-8e4a-ee6cc15d47b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1099.436422 62495.0194498 12858.564929264689\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Write your answer here\n",
        "min_val = dataframe['charges'].min()\n",
        "max_val = dataframe['charges'].max()\n",
        "mean_val = dataframe['charges'].mean()\n",
        "print(min_val, max_val, mean_val)\n",
        "# Create a histogram with 20 bins and blue bars\n",
        "dataframe['charges'].hist(bins=20, color='blue')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4lfVLhOC-mJ"
      },
      "source": [
        "Remember to commit your notebook to Jovian after every step, so that you don't lose your work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "SWpUrMl_C-mK"
      },
      "outputs": [],
      "source": [
        "!pip install jovian --upgrade -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "yzHiR_2HC-mK"
      },
      "outputs": [],
      "source": [
        "import jovian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsWjnHIVC-mM",
        "outputId": "319015c2-8bfb-45f8-d30c-ca975fc6b9d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] jovian.commit() is no longer required on Google Colab. If you ran this notebook from Jovian, \n",
            "then just save this file in Colab using Ctrl+S/Cmd+S and it will be updated on Jovian. \n",
            "Also, you can also delete this cell, it's no longer necessary.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "jovian.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiMapCYJC-mN"
      },
      "source": [
        "## Step 2: Prepare the dataset for training\n",
        "\n",
        "We need to convert the data from the Pandas dataframe into a PyTorch tensors for training. To do this, the first step is to convert it numpy arrays. If you've filled out `input_cols`, `categorial_cols` and `output_cols` correctly, this following function will perform the conversion to numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "8VVR02OTC-mO"
      },
      "outputs": [],
      "source": [
        "def dataframe_to_arrays(dataframe):\n",
        "    # Make a copy of the original dataframe\n",
        "    dataframe1 = dataframe.copy(deep=True)\n",
        "    # Convert non-numeric categorical columns to numbers\n",
        "    for col in categorical_cols:\n",
        "        dataframe1[col] = dataframe1[col].astype('category').cat.codes\n",
        "    # Extract input & outupts as numpy arrays\n",
        "    inputs_array = dataframe1[input_cols].to_numpy()\n",
        "    targets_array = dataframe1[output_cols].to_numpy()\n",
        "    return inputs_array, targets_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTdQ0rgTC-mP"
      },
      "source": [
        "Read through the [Pandas documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html) to understand how we're converting categorical variables into numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxpoLSujC-mQ",
        "outputId": "ed9efd77-1e1a-4b36-c961-fdaca5a0b56a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[57.     ,  0.     , 33.84945,  0.     ,  0.     ],\n",
              "        [44.     ,  0.     , 41.02005,  1.     ,  0.     ],\n",
              "        [58.     ,  0.     , 35.32575,  2.     ,  0.     ],\n",
              "        ...,\n",
              "        [59.     ,  0.     , 38.628  ,  2.     ,  0.     ],\n",
              "        [41.     ,  1.     , 31.968  ,  1.     ,  0.     ],\n",
              "        [36.     ,  0.     , 33.3222 ,  0.     ,  0.     ]]),\n",
              " array([[11603.959549 ],\n",
              "        [ 7862.672741 ],\n",
              "        [13335.221375 ],\n",
              "        ...,\n",
              "        [36172.3958694],\n",
              "        [ 6156.5903   ],\n",
              "        [ 5166.732284 ]]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "inputs_array, targets_array = dataframe_to_arrays(dataframe)\n",
        "inputs_array, targets_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LSJuJtVC-mR"
      },
      "source": [
        "**Q6: Convert the numpy arrays `inputs_array` and `targets_array` into PyTorch tensors. Make sure that the data type is `torch.float32`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "34cnwOdbC-mS"
      },
      "outputs": [],
      "source": [
        "inputs = torch.FloatTensor(inputs_array)\n",
        "targets = torch.FloatTensor(targets_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swoUIeWJC-mS",
        "outputId": "319a159c-30c2-4dec-a41e-b353feff6e72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "inputs.dtype, targets.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mo_A9xDC-mT"
      },
      "source": [
        "Next, we need to create PyTorch datasets & data loaders for training & validation. We'll start by creating a `TensorDataset`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "pD3MhIw9C-mT"
      },
      "outputs": [],
      "source": [
        "dataset = TensorDataset(inputs, targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdRcf_1SC-mU"
      },
      "source": [
        "**Q7: Pick a number between `0.1` and `0.2` to determine the fraction of data that will be used for creating the validation set. Then use `random_split` to create training & validation datasets.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "u23MGaygC-mV"
      },
      "outputs": [],
      "source": [
        "val_percent = 0.2 # between 0.1 and 0.2\n",
        "val_size = int(num_rows * val_percent)\n",
        "train_size = num_rows - val_size\n",
        "\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size]) # Use the random_split function to split dataset into 2 parts of the desired length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLvqkvddC-mW"
      },
      "source": [
        "Finally, we can create data loaders for training & validation.\n",
        "\n",
        "**Q8: Pick a batch size for the data loader.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Hb7rCMYjC-mX"
      },
      "outputs": [],
      "source": [
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "40tTCb4YC-mX"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey596KmBC-mY"
      },
      "source": [
        "Let's look at a batch of data to verify everything is working fine so far."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "8rcFMzFXC-mZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94f5a5a-6df9-457d-9e86-881b3b9d5783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs: tensor([[19.0000,  0.0000, 31.5240,  1.0000,  0.0000],\n",
            "        [36.0000,  1.0000, 31.1077,  1.0000,  1.0000],\n",
            "        [18.0000,  0.0000, 40.9035,  0.0000,  1.0000],\n",
            "        [38.0000,  0.0000, 32.1123,  1.0000,  0.0000],\n",
            "        [32.0000,  0.0000, 22.7772,  0.0000,  0.0000],\n",
            "        [18.0000,  0.0000, 33.4277,  0.0000,  0.0000],\n",
            "        [24.0000,  1.0000, 31.6350,  0.0000,  1.0000],\n",
            "        [47.0000,  1.0000, 40.1820,  1.0000,  0.0000],\n",
            "        [44.0000,  0.0000, 27.7500,  1.0000,  0.0000],\n",
            "        [40.0000,  1.0000, 29.2097,  1.0000,  0.0000],\n",
            "        [33.0000,  1.0000, 39.6825,  2.0000,  0.0000],\n",
            "        [38.0000,  0.0000, 30.6360,  0.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 27.3060,  1.0000,  0.0000],\n",
            "        [23.0000,  0.0000, 31.6239,  1.0000,  1.0000],\n",
            "        [35.0000,  1.0000, 27.1062,  3.0000,  1.0000],\n",
            "        [36.0000,  1.0000, 38.2173,  2.0000,  0.0000],\n",
            "        [53.0000,  1.0000, 23.7540,  1.0000,  0.0000],\n",
            "        [18.0000,  0.0000, 44.7108,  0.0000,  0.0000],\n",
            "        [42.0000,  0.0000, 36.8021,  1.0000,  0.0000],\n",
            "        [26.0000,  0.0000, 32.5840,  2.0000,  0.0000],\n",
            "        [45.0000,  0.0000, 36.7410,  0.0000,  0.0000],\n",
            "        [55.0000,  0.0000, 33.4554,  2.0000,  0.0000],\n",
            "        [54.0000,  0.0000, 27.3116,  3.0000,  0.0000],\n",
            "        [49.0000,  0.0000, 46.0317,  4.0000,  0.0000],\n",
            "        [35.0000,  1.0000, 30.0810,  1.0000,  0.0000],\n",
            "        [25.0000,  1.0000, 27.7334,  2.0000,  0.0000],\n",
            "        [27.0000,  0.0000, 22.2500,  3.0000,  1.0000],\n",
            "        [18.0000,  1.0000, 24.1758,  2.0000,  0.0000],\n",
            "        [35.0000,  1.0000, 33.8550,  1.0000,  0.0000],\n",
            "        [28.0000,  0.0000, 26.9952,  1.0000,  0.0000],\n",
            "        [56.0000,  1.0000, 35.6421,  1.0000,  0.0000],\n",
            "        [48.0000,  1.0000, 40.7037,  1.0000,  0.0000],\n",
            "        [57.0000,  0.0000, 25.7298,  0.0000,  0.0000],\n",
            "        [43.0000,  0.0000, 51.2820,  0.0000,  1.0000],\n",
            "        [43.0000,  1.0000, 42.2466,  2.0000,  1.0000],\n",
            "        [23.0000,  1.0000, 38.1840,  0.0000,  0.0000],\n",
            "        [53.0000,  0.0000, 29.6370,  2.0000,  0.0000],\n",
            "        [41.0000,  0.0000, 34.4322,  0.0000,  0.0000],\n",
            "        [63.0000,  1.0000, 24.0426,  1.0000,  0.0000],\n",
            "        [42.0000,  0.0000, 32.7228,  2.0000,  0.0000],\n",
            "        [45.0000,  1.0000, 44.1836,  0.0000,  0.0000],\n",
            "        [59.0000,  1.0000, 29.3040,  0.0000,  0.0000],\n",
            "        [48.0000,  0.0000, 30.3696,  1.0000,  0.0000],\n",
            "        [62.0000,  0.0000, 40.9146,  1.0000,  0.0000],\n",
            "        [59.0000,  0.0000, 29.6315,  3.0000,  0.0000],\n",
            "        [47.0000,  0.0000, 26.7510,  1.0000,  0.0000],\n",
            "        [51.0000,  0.0000, 40.3873,  3.0000,  0.0000],\n",
            "        [19.0000,  1.0000, 22.6717,  0.0000,  0.0000],\n",
            "        [63.0000,  0.0000, 40.9035,  0.0000,  0.0000],\n",
            "        [46.0000,  1.0000, 37.1184,  1.0000,  0.0000],\n",
            "        [43.0000,  0.0000, 29.6370,  2.0000,  1.0000],\n",
            "        [54.0000,  1.0000, 43.9560,  1.0000,  0.0000],\n",
            "        [30.0000,  1.0000, 31.8459,  3.0000,  1.0000],\n",
            "        [33.0000,  0.0000, 39.4383,  0.0000,  1.0000],\n",
            "        [40.0000,  1.0000, 27.8388,  0.0000,  0.0000],\n",
            "        [23.0000,  0.0000, 31.4241,  0.0000,  1.0000],\n",
            "        [26.0000,  0.0000, 44.6054,  0.0000,  0.0000],\n",
            "        [37.0000,  0.0000, 28.3661,  1.0000,  1.0000],\n",
            "        [31.0000,  1.0000, 31.7404,  1.0000,  0.0000],\n",
            "        [32.0000,  1.0000, 39.0720,  2.0000,  0.0000],\n",
            "        [28.0000,  0.0000, 38.5947,  0.0000,  0.0000],\n",
            "        [24.0000,  1.0000, 25.9740,  0.0000,  0.0000],\n",
            "        [18.0000,  1.0000, 37.8510,  0.0000,  0.0000],\n",
            "        [47.0000,  0.0000, 37.0130,  0.0000,  0.0000]])\n",
            "targets: tensor([[ 2284.8887],\n",
            "        [20358.1543],\n",
            "        [35426.4922],\n",
            "        [ 5854.8970],\n",
            "        [ 4453.3501],\n",
            "        [20917.9492],\n",
            "        [34444.5781],\n",
            "        [ 7906.8213],\n",
            "        [ 7471.0479],\n",
            "        [ 6261.5903],\n",
            "        [ 4792.1997],\n",
            "        [ 5275.8652],\n",
            "        [ 1800.4923],\n",
            "        [17961.6738],\n",
            "        [18974.7598],\n",
            "        [ 5472.6196],\n",
            "        [ 9864.1045],\n",
            "        [ 2173.2493],\n",
            "        [ 7486.6289],\n",
            "        [ 4472.9077],\n",
            "        [ 7198.1821],\n",
            "        [11644.3301],\n",
            "        [12230.1152],\n",
            "        [10757.6621],\n",
            "        [ 4651.4170],\n",
            "        [22776.6445],\n",
            "        [16092.0850],\n",
            "        [11646.3672],\n",
            "        [ 4656.0488],\n",
            "        [22823.1504],\n",
            "        [11527.7412],\n",
            "        [27899.5410],\n",
            "        [11593.9951],\n",
            "        [44945.9414],\n",
            "        [41709.2227],\n",
            "        [ 1790.3062],\n",
            "        [10927.7646],\n",
            "        [ 6061.6143],\n",
            "        [14062.8574],\n",
            "        [ 7487.5029],\n",
            "        [ 7299.4360],\n",
            "        [11508.4326],\n",
            "        [ 9258.4346],\n",
            "        [30987.6016],\n",
            "        [14095.0547],\n",
            "        [25711.8477],\n",
            "        [11208.0029],\n",
            "        [ 1592.9250],\n",
            "        [13610.2090],\n",
            "        [ 8167.8979],\n",
            "        [22029.0273],\n",
            "        [10241.5410],\n",
            "        [20331.0684],\n",
            "        [54032.6953],\n",
            "        [ 5307.3481],\n",
            "        [17673.2891],\n",
            "        [ 3137.2202],\n",
            "        [19890.9258],\n",
            "        [ 4158.7183],\n",
            "        [ 4577.2271],\n",
            "        [ 3485.7839],\n",
            "        [ 1930.2217],\n",
            "        [ 1114.2708],\n",
            "        [20461.2090]])\n"
          ]
        }
      ],
      "source": [
        "for xb, yb in train_loader:\n",
        "    print(\"inputs:\", xb)\n",
        "    print(\"targets:\", yb)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4zaSdQnC-ma"
      },
      "source": [
        "Let's save our work by committing to Jovian."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "NOv8P-XWC-mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa1615f-23f2-4c55-bebe-2abb7ad809b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] jovian.commit() is no longer required on Google Colab. If you ran this notebook from Jovian, \n",
            "then just save this file in Colab using Ctrl+S/Cmd+S and it will be updated on Jovian. \n",
            "Also, you can also delete this cell, it's no longer necessary.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJUzzczpC-mc"
      },
      "source": [
        "## Step 3: Create a Linear Regression Model\n",
        "\n",
        "Our model itself is a fairly straightforward linear regression (we'll build more complex models in the next assignment). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "GS-DyqniC-me"
      },
      "outputs": [],
      "source": [
        "input_size = len(input_cols)\n",
        "output_size = len(output_cols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZU7eSpdC-mf"
      },
      "source": [
        "**Q9: Complete the class definition below by filling out the constructor (`__init__`), `forward`, `training_step` and `validation_step` methods.**\n",
        "\n",
        "Hint: Think carefully about picking a good loss fuction (it's not cross entropy). Maybe try 2-3 of them and see which one works best. See https://pytorch.org/docs/stable/nn.functional.html#loss-functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "vXkzBDD1C-mh"
      },
      "outputs": [],
      "source": [
        "class InsuranceModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)                  # fill this (hint: use input_size & output_size defined above)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.linear(xb)                          # fill this\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        # Generate predictions\n",
        "        out = self(inputs)          \n",
        "        # Calcuate loss\n",
        "        loss = F.mse_loss(out, targets)                          # fill this\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch\n",
        "        # Generate predictions\n",
        "        out = self(inputs)\n",
        "        # Calculate loss\n",
        "        loss = F.mse_loss(out, targets)                           # fill this    \n",
        "        return {'val_loss': loss.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        return {'val_loss': epoch_loss.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result, num_epochs):\n",
        "        # Print result every 20th epoch\n",
        "        if (epoch+1) % 20 == 0 or epoch == num_epochs-1:\n",
        "            print(\"Epoch [{}], val_loss: {:.4f}\".format(epoch+1, result['val_loss']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5z7dT_aC-mi"
      },
      "source": [
        "Let us create a model using the `InsuranceModel` class. You may need to come back later and re-run the next cell to reinitialize the model, in case the loss becomes `nan` or `infinity`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "s3rBBzuRC-mj"
      },
      "outputs": [],
      "source": [
        "model = InsuranceModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beD4MgMcC-mk"
      },
      "source": [
        "Let's check out the weights and biases of the model using `model.parameters`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "1cH9cFp3C-mk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0afe236f-be95-4a86-9c47-cc6561b6d8dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.1527, -0.3679,  0.1981, -0.1100,  0.0119]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.4163], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "list(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymdEZqTRC-ml"
      },
      "source": [
        "One final commit before we train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "nxfGIcn1C-ml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47bb156-4a20-4b5f-d101-f310439556c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] jovian.commit() is no longer required on Google Colab. If you ran this notebook from Jovian, \n",
            "then just save this file in Colab using Ctrl+S/Cmd+S and it will be updated on Jovian. \n",
            "Also, you can also delete this cell, it's no longer necessary.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfWMnlQoC-mm"
      },
      "source": [
        "## Step 4: Train the model to fit the data\n",
        "\n",
        "To train our model, we'll use the same `fit` function explained in the lecture. That's the benefit of defining a generic training loop - you can use it for any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "K5CTCfMjC-mm"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result, epochs)\n",
        "        history.append(result)\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWhEDrGOC-mm"
      },
      "source": [
        "**Q10: Use the `evaluate` function to calculate the loss on the validation set before training.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "51rViD6WC-mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad9bcbd-a748-4a27-e3d7-ecf2594096f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'val_loss': 280372800.0}\n"
          ]
        }
      ],
      "source": [
        "result = evaluate(model, val_loader) # Use the the evaluate function\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cPxE0ftC-mn"
      },
      "source": [
        "\n",
        "We are now ready to train the model. You may need to run the training loop many times, for different number of epochs and with different learning rates, to get a good result. Also, if your loss becomes too large (or `nan`), you may have to re-initialize the model by running the cell `model = InsuranceModel()`. Experiment with this for a while, and try to get to as low a loss as possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vwbBgJIC-mn"
      },
      "source": [
        "**Q11: Train the model 4-5 times with different learning rates & for different number of epochs.**\n",
        "\n",
        "Hint: Vary learning rates by orders of 10 (e.g. `1e-2`, `1e-3`, `1e-4`, `1e-5`, `1e-6`) to figure out what works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "rF0rROSiC-mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "316072f2-f3db-4bab-b6dd-659b285286d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20], val_loss: 111660912.0000\n",
            "Epoch [40], val_loss: 111445648.0000\n",
            "Epoch [60], val_loss: 111443624.0000\n",
            "Epoch [80], val_loss: 111206008.0000\n",
            "Epoch [100], val_loss: 110944912.0000\n",
            "Epoch [120], val_loss: 110790328.0000\n",
            "Epoch [140], val_loss: 110688944.0000\n",
            "Epoch [160], val_loss: 110490192.0000\n",
            "Epoch [180], val_loss: 110371120.0000\n",
            "Epoch [200], val_loss: 110271840.0000\n",
            "Epoch [220], val_loss: 110014832.0000\n",
            "Epoch [240], val_loss: 109875456.0000\n",
            "Epoch [260], val_loss: 109679752.0000\n",
            "Epoch [280], val_loss: 109577200.0000\n",
            "Epoch [300], val_loss: 109419184.0000\n",
            "Epoch [320], val_loss: 109266992.0000\n",
            "Epoch [340], val_loss: 109073888.0000\n",
            "Epoch [360], val_loss: 108878472.0000\n",
            "Epoch [380], val_loss: 108773184.0000\n",
            "Epoch [400], val_loss: 108664656.0000\n",
            "Epoch [420], val_loss: 108502512.0000\n",
            "Epoch [440], val_loss: 108315848.0000\n",
            "Epoch [460], val_loss: 108121976.0000\n",
            "Epoch [480], val_loss: 107981104.0000\n",
            "Epoch [500], val_loss: 107963952.0000\n",
            "Epoch [520], val_loss: 107747952.0000\n",
            "Epoch [540], val_loss: 107552712.0000\n",
            "Epoch [560], val_loss: 107461992.0000\n",
            "Epoch [580], val_loss: 107322936.0000\n",
            "Epoch [600], val_loss: 107116824.0000\n",
            "Epoch [620], val_loss: 106932472.0000\n",
            "Epoch [640], val_loss: 106873168.0000\n",
            "Epoch [660], val_loss: 106681536.0000\n",
            "Epoch [680], val_loss: 106574976.0000\n",
            "Epoch [700], val_loss: 106397456.0000\n",
            "Epoch [720], val_loss: 106315320.0000\n",
            "Epoch [740], val_loss: 106104304.0000\n",
            "Epoch [760], val_loss: 105943616.0000\n",
            "Epoch [780], val_loss: 105803120.0000\n",
            "Epoch [800], val_loss: 105689360.0000\n",
            "Epoch [820], val_loss: 105620312.0000\n",
            "Epoch [840], val_loss: 105317208.0000\n",
            "Epoch [860], val_loss: 105216680.0000\n",
            "Epoch [880], val_loss: 105119992.0000\n",
            "Epoch [900], val_loss: 104959952.0000\n",
            "Epoch [920], val_loss: 104827248.0000\n",
            "Epoch [940], val_loss: 104664880.0000\n",
            "Epoch [960], val_loss: 104517192.0000\n",
            "Epoch [980], val_loss: 104406640.0000\n",
            "Epoch [1000], val_loss: 104244352.0000\n"
          ]
        }
      ],
      "source": [
        "epochs = 1000\n",
        "lr = 1e-5\n",
        "history1 = fit(epochs, lr, model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "E3xL2_82C-mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09260542-d4f0-4597-87e2-3b1366eca446"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20], val_loss: 37397612.0000\n",
            "Epoch [40], val_loss: 37493688.0000\n",
            "Epoch [60], val_loss: 37415760.0000\n",
            "Epoch [80], val_loss: 37429360.0000\n",
            "Epoch [100], val_loss: 37594352.0000\n",
            "Epoch [120], val_loss: 37983680.0000\n",
            "Epoch [140], val_loss: 38247996.0000\n",
            "Epoch [160], val_loss: 37433016.0000\n",
            "Epoch [180], val_loss: 37993580.0000\n",
            "Epoch [200], val_loss: 37625432.0000\n",
            "Epoch [220], val_loss: 37944656.0000\n",
            "Epoch [240], val_loss: 37499576.0000\n",
            "Epoch [260], val_loss: 37416708.0000\n",
            "Epoch [280], val_loss: 37906696.0000\n",
            "Epoch [300], val_loss: 37584552.0000\n",
            "Epoch [320], val_loss: 38403720.0000\n",
            "Epoch [340], val_loss: 37354552.0000\n",
            "Epoch [360], val_loss: 37540924.0000\n",
            "Epoch [380], val_loss: 38101660.0000\n",
            "Epoch [400], val_loss: 37980484.0000\n",
            "Epoch [420], val_loss: 37633080.0000\n",
            "Epoch [440], val_loss: 38085188.0000\n",
            "Epoch [460], val_loss: 37447196.0000\n",
            "Epoch [480], val_loss: 37339948.0000\n",
            "Epoch [500], val_loss: 37438064.0000\n",
            "Epoch [520], val_loss: 37480228.0000\n",
            "Epoch [540], val_loss: 37459720.0000\n",
            "Epoch [560], val_loss: 37344456.0000\n",
            "Epoch [580], val_loss: 37333308.0000\n",
            "Epoch [600], val_loss: 37385124.0000\n",
            "Epoch [620], val_loss: 38725508.0000\n",
            "Epoch [640], val_loss: 37323232.0000\n",
            "Epoch [660], val_loss: 37320876.0000\n",
            "Epoch [680], val_loss: 37439584.0000\n",
            "Epoch [700], val_loss: 37334048.0000\n",
            "Epoch [720], val_loss: 37356424.0000\n",
            "Epoch [740], val_loss: 37693700.0000\n",
            "Epoch [760], val_loss: 38059796.0000\n",
            "Epoch [780], val_loss: 38049084.0000\n",
            "Epoch [800], val_loss: 37406312.0000\n",
            "Epoch [820], val_loss: 37885680.0000\n",
            "Epoch [840], val_loss: 37936144.0000\n",
            "Epoch [860], val_loss: 37434724.0000\n",
            "Epoch [880], val_loss: 37323144.0000\n",
            "Epoch [900], val_loss: 37347640.0000\n",
            "Epoch [920], val_loss: 37530020.0000\n",
            "Epoch [940], val_loss: 37342808.0000\n",
            "Epoch [960], val_loss: 37421540.0000\n",
            "Epoch [980], val_loss: 37555544.0000\n",
            "Epoch [1000], val_loss: 38158480.0000\n",
            "Epoch [1020], val_loss: 37670408.0000\n",
            "Epoch [1040], val_loss: 37592432.0000\n",
            "Epoch [1060], val_loss: 37407216.0000\n",
            "Epoch [1080], val_loss: 38043868.0000\n",
            "Epoch [1100], val_loss: 37466884.0000\n",
            "Epoch [1120], val_loss: 37444312.0000\n",
            "Epoch [1140], val_loss: 37315488.0000\n",
            "Epoch [1160], val_loss: 37290708.0000\n",
            "Epoch [1180], val_loss: 37300280.0000\n",
            "Epoch [1200], val_loss: 38090632.0000\n",
            "Epoch [1220], val_loss: 37584920.0000\n",
            "Epoch [1240], val_loss: 37541044.0000\n",
            "Epoch [1260], val_loss: 37321408.0000\n",
            "Epoch [1280], val_loss: 37327268.0000\n",
            "Epoch [1300], val_loss: 37374800.0000\n",
            "Epoch [1320], val_loss: 37748256.0000\n",
            "Epoch [1340], val_loss: 37305920.0000\n",
            "Epoch [1360], val_loss: 37917624.0000\n",
            "Epoch [1380], val_loss: 38535372.0000\n",
            "Epoch [1400], val_loss: 37286872.0000\n",
            "Epoch [1420], val_loss: 37298924.0000\n",
            "Epoch [1440], val_loss: 37730680.0000\n",
            "Epoch [1460], val_loss: 37353800.0000\n",
            "Epoch [1480], val_loss: 37268804.0000\n",
            "Epoch [1500], val_loss: 37381456.0000\n",
            "Epoch [1520], val_loss: 37570632.0000\n",
            "Epoch [1540], val_loss: 37275608.0000\n",
            "Epoch [1560], val_loss: 37378628.0000\n",
            "Epoch [1580], val_loss: 37401636.0000\n",
            "Epoch [1600], val_loss: 37278076.0000\n",
            "Epoch [1620], val_loss: 37259656.0000\n",
            "Epoch [1640], val_loss: 38252696.0000\n",
            "Epoch [1660], val_loss: 37383472.0000\n",
            "Epoch [1680], val_loss: 37421776.0000\n",
            "Epoch [1700], val_loss: 37260996.0000\n",
            "Epoch [1720], val_loss: 37279016.0000\n",
            "Epoch [1740], val_loss: 37258764.0000\n",
            "Epoch [1760], val_loss: 37456300.0000\n",
            "Epoch [1780], val_loss: 37910156.0000\n",
            "Epoch [1800], val_loss: 37464248.0000\n",
            "Epoch [1820], val_loss: 37304888.0000\n",
            "Epoch [1840], val_loss: 37718192.0000\n",
            "Epoch [1860], val_loss: 37946204.0000\n",
            "Epoch [1880], val_loss: 37587272.0000\n",
            "Epoch [1900], val_loss: 37409696.0000\n",
            "Epoch [1920], val_loss: 37531152.0000\n",
            "Epoch [1940], val_loss: 37245792.0000\n",
            "Epoch [1960], val_loss: 37263336.0000\n",
            "Epoch [1980], val_loss: 37479680.0000\n",
            "Epoch [2000], val_loss: 38644800.0000\n",
            "Epoch [2020], val_loss: 37644196.0000\n",
            "Epoch [2040], val_loss: 38154244.0000\n",
            "Epoch [2060], val_loss: 37519684.0000\n",
            "Epoch [2080], val_loss: 37248664.0000\n",
            "Epoch [2100], val_loss: 37555684.0000\n",
            "Epoch [2120], val_loss: 37392912.0000\n",
            "Epoch [2140], val_loss: 37236864.0000\n",
            "Epoch [2160], val_loss: 37235632.0000\n",
            "Epoch [2180], val_loss: 37250904.0000\n",
            "Epoch [2200], val_loss: 37229964.0000\n",
            "Epoch [2220], val_loss: 37405720.0000\n",
            "Epoch [2240], val_loss: 37236904.0000\n",
            "Epoch [2260], val_loss: 38765844.0000\n",
            "Epoch [2280], val_loss: 37235224.0000\n",
            "Epoch [2300], val_loss: 37220732.0000\n",
            "Epoch [2320], val_loss: 37387928.0000\n",
            "Epoch [2340], val_loss: 37285032.0000\n",
            "Epoch [2360], val_loss: 37244956.0000\n",
            "Epoch [2380], val_loss: 37293112.0000\n",
            "Epoch [2400], val_loss: 37221768.0000\n",
            "Epoch [2420], val_loss: 38279300.0000\n",
            "Epoch [2440], val_loss: 38620292.0000\n",
            "Epoch [2460], val_loss: 37253540.0000\n",
            "Epoch [2480], val_loss: 38031832.0000\n",
            "Epoch [2500], val_loss: 37225412.0000\n",
            "Epoch [2520], val_loss: 37268868.0000\n",
            "Epoch [2540], val_loss: 37386628.0000\n",
            "Epoch [2560], val_loss: 37275996.0000\n",
            "Epoch [2580], val_loss: 37748016.0000\n",
            "Epoch [2600], val_loss: 37214972.0000\n",
            "Epoch [2620], val_loss: 37227024.0000\n",
            "Epoch [2640], val_loss: 37809480.0000\n",
            "Epoch [2660], val_loss: 37350360.0000\n",
            "Epoch [2680], val_loss: 37211624.0000\n",
            "Epoch [2700], val_loss: 37240372.0000\n",
            "Epoch [2720], val_loss: 37491876.0000\n",
            "Epoch [2740], val_loss: 37860368.0000\n",
            "Epoch [2760], val_loss: 37223832.0000\n",
            "Epoch [2780], val_loss: 38235320.0000\n",
            "Epoch [2800], val_loss: 37685200.0000\n",
            "Epoch [2820], val_loss: 38397832.0000\n",
            "Epoch [2840], val_loss: 37995232.0000\n",
            "Epoch [2860], val_loss: 37740276.0000\n",
            "Epoch [2880], val_loss: 37227632.0000\n",
            "Epoch [2900], val_loss: 37249208.0000\n",
            "Epoch [2920], val_loss: 37386832.0000\n",
            "Epoch [2940], val_loss: 37567276.0000\n",
            "Epoch [2960], val_loss: 37481016.0000\n",
            "Epoch [2980], val_loss: 37458388.0000\n",
            "Epoch [3000], val_loss: 37426648.0000\n",
            "Epoch [3020], val_loss: 37197460.0000\n",
            "Epoch [3040], val_loss: 37514496.0000\n",
            "Epoch [3060], val_loss: 37824708.0000\n",
            "Epoch [3080], val_loss: 37198120.0000\n",
            "Epoch [3100], val_loss: 37395980.0000\n",
            "Epoch [3120], val_loss: 37209776.0000\n",
            "Epoch [3140], val_loss: 37309664.0000\n",
            "Epoch [3160], val_loss: 37189832.0000\n",
            "Epoch [3180], val_loss: 37977588.0000\n",
            "Epoch [3200], val_loss: 37216300.0000\n",
            "Epoch [3220], val_loss: 37530432.0000\n",
            "Epoch [3240], val_loss: 37662776.0000\n",
            "Epoch [3260], val_loss: 37195068.0000\n",
            "Epoch [3280], val_loss: 37500152.0000\n",
            "Epoch [3300], val_loss: 37491356.0000\n",
            "Epoch [3320], val_loss: 37598456.0000\n",
            "Epoch [3340], val_loss: 37351428.0000\n",
            "Epoch [3360], val_loss: 37196636.0000\n",
            "Epoch [3380], val_loss: 37617756.0000\n",
            "Epoch [3400], val_loss: 37187440.0000\n",
            "Epoch [3420], val_loss: 37429464.0000\n",
            "Epoch [3440], val_loss: 37228960.0000\n",
            "Epoch [3460], val_loss: 37325548.0000\n",
            "Epoch [3480], val_loss: 38080788.0000\n",
            "Epoch [3500], val_loss: 37169204.0000\n",
            "Epoch [3520], val_loss: 37272128.0000\n",
            "Epoch [3540], val_loss: 37182604.0000\n",
            "Epoch [3560], val_loss: 37311112.0000\n",
            "Epoch [3580], val_loss: 37556996.0000\n",
            "Epoch [3600], val_loss: 37213792.0000\n",
            "Epoch [3620], val_loss: 37175044.0000\n",
            "Epoch [3640], val_loss: 37215512.0000\n",
            "Epoch [3660], val_loss: 37359600.0000\n",
            "Epoch [3680], val_loss: 37176432.0000\n",
            "Epoch [3700], val_loss: 37396412.0000\n",
            "Epoch [3720], val_loss: 38017036.0000\n",
            "Epoch [3740], val_loss: 37173260.0000\n",
            "Epoch [3760], val_loss: 37250104.0000\n",
            "Epoch [3780], val_loss: 37212896.0000\n",
            "Epoch [3800], val_loss: 37576192.0000\n",
            "Epoch [3820], val_loss: 37501416.0000\n",
            "Epoch [3840], val_loss: 37161388.0000\n",
            "Epoch [3860], val_loss: 37760256.0000\n",
            "Epoch [3880], val_loss: 37262320.0000\n",
            "Epoch [3900], val_loss: 37224376.0000\n",
            "Epoch [3920], val_loss: 37372288.0000\n",
            "Epoch [3940], val_loss: 37314584.0000\n",
            "Epoch [3960], val_loss: 37510840.0000\n",
            "Epoch [3980], val_loss: 37262960.0000\n",
            "Epoch [4000], val_loss: 37249712.0000\n",
            "Epoch [4020], val_loss: 37525404.0000\n",
            "Epoch [4040], val_loss: 37165508.0000\n",
            "Epoch [4060], val_loss: 37279616.0000\n",
            "Epoch [4080], val_loss: 38405752.0000\n",
            "Epoch [4100], val_loss: 37277328.0000\n",
            "Epoch [4120], val_loss: 37155148.0000\n",
            "Epoch [4140], val_loss: 37157560.0000\n",
            "Epoch [4160], val_loss: 37195488.0000\n",
            "Epoch [4180], val_loss: 37964036.0000\n",
            "Epoch [4200], val_loss: 37690988.0000\n",
            "Epoch [4220], val_loss: 37521372.0000\n",
            "Epoch [4240], val_loss: 37180656.0000\n",
            "Epoch [4260], val_loss: 37168980.0000\n",
            "Epoch [4280], val_loss: 37466060.0000\n",
            "Epoch [4300], val_loss: 37182268.0000\n",
            "Epoch [4320], val_loss: 37160064.0000\n",
            "Epoch [4340], val_loss: 37955880.0000\n",
            "Epoch [4360], val_loss: 37305472.0000\n",
            "Epoch [4380], val_loss: 37158000.0000\n",
            "Epoch [4400], val_loss: 37464092.0000\n",
            "Epoch [4420], val_loss: 37800328.0000\n",
            "Epoch [4440], val_loss: 37233168.0000\n",
            "Epoch [4460], val_loss: 37678616.0000\n",
            "Epoch [4480], val_loss: 37406384.0000\n",
            "Epoch [4500], val_loss: 37149664.0000\n",
            "Epoch [4520], val_loss: 37199616.0000\n",
            "Epoch [4540], val_loss: 37144360.0000\n",
            "Epoch [4560], val_loss: 37166044.0000\n",
            "Epoch [4580], val_loss: 37313520.0000\n",
            "Epoch [4600], val_loss: 37152152.0000\n",
            "Epoch [4620], val_loss: 37788296.0000\n",
            "Epoch [4640], val_loss: 37609612.0000\n",
            "Epoch [4660], val_loss: 37312600.0000\n",
            "Epoch [4680], val_loss: 37336648.0000\n",
            "Epoch [4700], val_loss: 37225804.0000\n",
            "Epoch [4720], val_loss: 37174268.0000\n",
            "Epoch [4740], val_loss: 37193740.0000\n",
            "Epoch [4760], val_loss: 38225152.0000\n",
            "Epoch [4780], val_loss: 38313716.0000\n",
            "Epoch [4800], val_loss: 37546072.0000\n",
            "Epoch [4820], val_loss: 37147468.0000\n",
            "Epoch [4840], val_loss: 37250856.0000\n",
            "Epoch [4860], val_loss: 37141876.0000\n",
            "Epoch [4880], val_loss: 37841088.0000\n",
            "Epoch [4900], val_loss: 37654536.0000\n",
            "Epoch [4920], val_loss: 37195432.0000\n",
            "Epoch [4940], val_loss: 37138452.0000\n",
            "Epoch [4960], val_loss: 37317200.0000\n",
            "Epoch [4980], val_loss: 37173064.0000\n",
            "Epoch [5000], val_loss: 37137912.0000\n",
            "Epoch [5020], val_loss: 37960848.0000\n",
            "Epoch [5040], val_loss: 37783756.0000\n",
            "Epoch [5060], val_loss: 37147024.0000\n",
            "Epoch [5080], val_loss: 37495060.0000\n",
            "Epoch [5100], val_loss: 37142936.0000\n",
            "Epoch [5120], val_loss: 37456668.0000\n",
            "Epoch [5140], val_loss: 37141744.0000\n",
            "Epoch [5160], val_loss: 37710888.0000\n",
            "Epoch [5180], val_loss: 37202016.0000\n",
            "Epoch [5200], val_loss: 37561000.0000\n",
            "Epoch [5220], val_loss: 37192660.0000\n",
            "Epoch [5240], val_loss: 37133408.0000\n",
            "Epoch [5260], val_loss: 37438128.0000\n",
            "Epoch [5280], val_loss: 37247448.0000\n",
            "Epoch [5300], val_loss: 37358752.0000\n",
            "Epoch [5320], val_loss: 37188372.0000\n",
            "Epoch [5340], val_loss: 37613056.0000\n",
            "Epoch [5360], val_loss: 37129440.0000\n",
            "Epoch [5380], val_loss: 37968856.0000\n",
            "Epoch [5400], val_loss: 37777660.0000\n",
            "Epoch [5420], val_loss: 37745016.0000\n",
            "Epoch [5440], val_loss: 37796012.0000\n",
            "Epoch [5460], val_loss: 37141172.0000\n",
            "Epoch [5480], val_loss: 37137464.0000\n",
            "Epoch [5500], val_loss: 37177168.0000\n",
            "Epoch [5520], val_loss: 37173528.0000\n",
            "Epoch [5540], val_loss: 37194632.0000\n",
            "Epoch [5560], val_loss: 37186768.0000\n",
            "Epoch [5580], val_loss: 37141264.0000\n",
            "Epoch [5600], val_loss: 37266740.0000\n",
            "Epoch [5620], val_loss: 37160044.0000\n",
            "Epoch [5640], val_loss: 37129320.0000\n",
            "Epoch [5660], val_loss: 37450752.0000\n",
            "Epoch [5680], val_loss: 37295852.0000\n",
            "Epoch [5700], val_loss: 37163824.0000\n",
            "Epoch [5720], val_loss: 37393544.0000\n",
            "Epoch [5740], val_loss: 38675568.0000\n",
            "Epoch [5760], val_loss: 38401976.0000\n",
            "Epoch [5780], val_loss: 37675120.0000\n",
            "Epoch [5800], val_loss: 37127960.0000\n",
            "Epoch [5820], val_loss: 37233352.0000\n",
            "Epoch [5840], val_loss: 37205492.0000\n",
            "Epoch [5860], val_loss: 37247176.0000\n",
            "Epoch [5880], val_loss: 37443796.0000\n",
            "Epoch [5900], val_loss: 37189880.0000\n",
            "Epoch [5920], val_loss: 37785400.0000\n",
            "Epoch [5940], val_loss: 37320312.0000\n",
            "Epoch [5960], val_loss: 38062864.0000\n",
            "Epoch [5980], val_loss: 37432584.0000\n",
            "Epoch [6000], val_loss: 37175112.0000\n",
            "Epoch [6020], val_loss: 37564140.0000\n",
            "Epoch [6040], val_loss: 37130584.0000\n",
            "Epoch [6060], val_loss: 37913144.0000\n",
            "Epoch [6080], val_loss: 38633576.0000\n",
            "Epoch [6100], val_loss: 37518920.0000\n",
            "Epoch [6120], val_loss: 37134492.0000\n",
            "Epoch [6140], val_loss: 37280076.0000\n",
            "Epoch [6160], val_loss: 37138352.0000\n",
            "Epoch [6180], val_loss: 37118016.0000\n",
            "Epoch [6200], val_loss: 37394660.0000\n",
            "Epoch [6220], val_loss: 37145348.0000\n",
            "Epoch [6240], val_loss: 38078908.0000\n",
            "Epoch [6260], val_loss: 37334016.0000\n",
            "Epoch [6280], val_loss: 37885992.0000\n",
            "Epoch [6300], val_loss: 37140100.0000\n",
            "Epoch [6320], val_loss: 37227388.0000\n",
            "Epoch [6340], val_loss: 37182972.0000\n",
            "Epoch [6360], val_loss: 37137120.0000\n",
            "Epoch [6380], val_loss: 37109308.0000\n",
            "Epoch [6400], val_loss: 37148032.0000\n",
            "Epoch [6420], val_loss: 37353572.0000\n",
            "Epoch [6440], val_loss: 37254044.0000\n",
            "Epoch [6460], val_loss: 37450552.0000\n",
            "Epoch [6480], val_loss: 37126820.0000\n",
            "Epoch [6500], val_loss: 37852980.0000\n",
            "Epoch [6520], val_loss: 37435380.0000\n",
            "Epoch [6540], val_loss: 37245280.0000\n",
            "Epoch [6560], val_loss: 37254288.0000\n",
            "Epoch [6580], val_loss: 37282220.0000\n",
            "Epoch [6600], val_loss: 37115008.0000\n",
            "Epoch [6620], val_loss: 37960916.0000\n",
            "Epoch [6640], val_loss: 37268168.0000\n",
            "Epoch [6660], val_loss: 37224000.0000\n",
            "Epoch [6680], val_loss: 37990704.0000\n",
            "Epoch [6700], val_loss: 37237428.0000\n",
            "Epoch [6720], val_loss: 37539440.0000\n",
            "Epoch [6740], val_loss: 37833400.0000\n",
            "Epoch [6760], val_loss: 37829448.0000\n",
            "Epoch [6780], val_loss: 37110960.0000\n",
            "Epoch [6800], val_loss: 37135484.0000\n",
            "Epoch [6820], val_loss: 37460208.0000\n",
            "Epoch [6840], val_loss: 37425484.0000\n",
            "Epoch [6860], val_loss: 37122436.0000\n",
            "Epoch [6880], val_loss: 37120244.0000\n",
            "Epoch [6900], val_loss: 37119964.0000\n",
            "Epoch [6920], val_loss: 38219460.0000\n",
            "Epoch [6940], val_loss: 37192860.0000\n",
            "Epoch [6960], val_loss: 37171324.0000\n",
            "Epoch [6980], val_loss: 38882584.0000\n",
            "Epoch [7000], val_loss: 37110832.0000\n",
            "Epoch [7020], val_loss: 37261664.0000\n",
            "Epoch [7040], val_loss: 37767836.0000\n",
            "Epoch [7060], val_loss: 37189624.0000\n",
            "Epoch [7080], val_loss: 37118352.0000\n",
            "Epoch [7100], val_loss: 37262484.0000\n",
            "Epoch [7120], val_loss: 37122668.0000\n",
            "Epoch [7140], val_loss: 37641712.0000\n",
            "Epoch [7160], val_loss: 37200480.0000\n",
            "Epoch [7180], val_loss: 37846504.0000\n",
            "Epoch [7200], val_loss: 37174420.0000\n",
            "Epoch [7220], val_loss: 37687328.0000\n",
            "Epoch [7240], val_loss: 37119324.0000\n",
            "Epoch [7260], val_loss: 37395080.0000\n",
            "Epoch [7280], val_loss: 37587632.0000\n",
            "Epoch [7300], val_loss: 37556236.0000\n",
            "Epoch [7320], val_loss: 37376040.0000\n",
            "Epoch [7340], val_loss: 37591384.0000\n",
            "Epoch [7360], val_loss: 38100484.0000\n",
            "Epoch [7380], val_loss: 37511272.0000\n",
            "Epoch [7400], val_loss: 37144076.0000\n",
            "Epoch [7420], val_loss: 38412032.0000\n",
            "Epoch [7440], val_loss: 37820360.0000\n",
            "Epoch [7460], val_loss: 37449560.0000\n",
            "Epoch [7480], val_loss: 37193872.0000\n",
            "Epoch [7500], val_loss: 37376104.0000\n",
            "Epoch [7520], val_loss: 37112484.0000\n",
            "Epoch [7540], val_loss: 37736460.0000\n",
            "Epoch [7560], val_loss: 37277752.0000\n",
            "Epoch [7580], val_loss: 37165212.0000\n",
            "Epoch [7600], val_loss: 37168656.0000\n",
            "Epoch [7620], val_loss: 37302540.0000\n",
            "Epoch [7640], val_loss: 37422692.0000\n",
            "Epoch [7660], val_loss: 37489484.0000\n",
            "Epoch [7680], val_loss: 37102596.0000\n",
            "Epoch [7700], val_loss: 37198020.0000\n",
            "Epoch [7720], val_loss: 37507820.0000\n",
            "Epoch [7740], val_loss: 37139248.0000\n",
            "Epoch [7760], val_loss: 37218656.0000\n",
            "Epoch [7780], val_loss: 37183000.0000\n",
            "Epoch [7800], val_loss: 37328888.0000\n",
            "Epoch [7820], val_loss: 37268612.0000\n",
            "Epoch [7840], val_loss: 37368680.0000\n",
            "Epoch [7860], val_loss: 37426344.0000\n",
            "Epoch [7880], val_loss: 37226348.0000\n",
            "Epoch [7900], val_loss: 37103472.0000\n",
            "Epoch [7920], val_loss: 37123152.0000\n",
            "Epoch [7940], val_loss: 37444368.0000\n",
            "Epoch [7960], val_loss: 37138704.0000\n",
            "Epoch [7980], val_loss: 37281544.0000\n",
            "Epoch [8000], val_loss: 37104768.0000\n",
            "Epoch [8020], val_loss: 37144780.0000\n",
            "Epoch [8040], val_loss: 37219052.0000\n",
            "Epoch [8060], val_loss: 37118648.0000\n",
            "Epoch [8080], val_loss: 37127320.0000\n",
            "Epoch [8100], val_loss: 37230048.0000\n",
            "Epoch [8120], val_loss: 37410540.0000\n",
            "Epoch [8140], val_loss: 37656816.0000\n",
            "Epoch [8160], val_loss: 37395068.0000\n",
            "Epoch [8180], val_loss: 37271796.0000\n",
            "Epoch [8200], val_loss: 37507416.0000\n",
            "Epoch [8220], val_loss: 37552152.0000\n",
            "Epoch [8240], val_loss: 38546680.0000\n",
            "Epoch [8260], val_loss: 38009912.0000\n",
            "Epoch [8280], val_loss: 37149016.0000\n",
            "Epoch [8300], val_loss: 38185592.0000\n",
            "Epoch [8320], val_loss: 37115520.0000\n",
            "Epoch [8340], val_loss: 37126224.0000\n",
            "Epoch [8360], val_loss: 37530504.0000\n",
            "Epoch [8380], val_loss: 37117392.0000\n",
            "Epoch [8400], val_loss: 37117312.0000\n",
            "Epoch [8420], val_loss: 37113652.0000\n",
            "Epoch [8440], val_loss: 37547092.0000\n",
            "Epoch [8460], val_loss: 37847580.0000\n",
            "Epoch [8480], val_loss: 37170640.0000\n",
            "Epoch [8500], val_loss: 37174276.0000\n",
            "Epoch [8520], val_loss: 37099104.0000\n",
            "Epoch [8540], val_loss: 37208644.0000\n",
            "Epoch [8560], val_loss: 37610560.0000\n",
            "Epoch [8580], val_loss: 37583688.0000\n",
            "Epoch [8600], val_loss: 38091088.0000\n",
            "Epoch [8620], val_loss: 37182500.0000\n",
            "Epoch [8640], val_loss: 38424216.0000\n",
            "Epoch [8660], val_loss: 38495024.0000\n",
            "Epoch [8680], val_loss: 37212648.0000\n",
            "Epoch [8700], val_loss: 37990516.0000\n",
            "Epoch [8720], val_loss: 37184016.0000\n",
            "Epoch [8740], val_loss: 37107500.0000\n",
            "Epoch [8760], val_loss: 37142252.0000\n",
            "Epoch [8780], val_loss: 37443456.0000\n",
            "Epoch [8800], val_loss: 37560436.0000\n",
            "Epoch [8820], val_loss: 37882804.0000\n",
            "Epoch [8840], val_loss: 37237208.0000\n",
            "Epoch [8860], val_loss: 37170992.0000\n",
            "Epoch [8880], val_loss: 38108244.0000\n",
            "Epoch [8900], val_loss: 37672044.0000\n",
            "Epoch [8920], val_loss: 37653620.0000\n",
            "Epoch [8940], val_loss: 37101132.0000\n",
            "Epoch [8960], val_loss: 37945092.0000\n",
            "Epoch [8980], val_loss: 37705620.0000\n",
            "Epoch [9000], val_loss: 37135464.0000\n",
            "Epoch [9020], val_loss: 38216024.0000\n",
            "Epoch [9040], val_loss: 37173880.0000\n",
            "Epoch [9060], val_loss: 38231120.0000\n",
            "Epoch [9080], val_loss: 37255944.0000\n",
            "Epoch [9100], val_loss: 37092004.0000\n",
            "Epoch [9120], val_loss: 38407184.0000\n",
            "Epoch [9140], val_loss: 37100412.0000\n",
            "Epoch [9160], val_loss: 37109628.0000\n",
            "Epoch [9180], val_loss: 37173768.0000\n",
            "Epoch [9200], val_loss: 37313336.0000\n",
            "Epoch [9220], val_loss: 37173304.0000\n",
            "Epoch [9240], val_loss: 38642936.0000\n",
            "Epoch [9260], val_loss: 37099184.0000\n",
            "Epoch [9280], val_loss: 37997180.0000\n",
            "Epoch [9300], val_loss: 37483080.0000\n",
            "Epoch [9320], val_loss: 37646560.0000\n",
            "Epoch [9340], val_loss: 37106124.0000\n",
            "Epoch [9360], val_loss: 37906196.0000\n",
            "Epoch [9380], val_loss: 37953204.0000\n",
            "Epoch [9400], val_loss: 37235492.0000\n",
            "Epoch [9420], val_loss: 37199720.0000\n",
            "Epoch [9440], val_loss: 37327128.0000\n",
            "Epoch [9460], val_loss: 37552492.0000\n",
            "Epoch [9480], val_loss: 37144096.0000\n",
            "Epoch [9500], val_loss: 38206360.0000\n",
            "Epoch [9520], val_loss: 37579544.0000\n",
            "Epoch [9540], val_loss: 37236376.0000\n",
            "Epoch [9560], val_loss: 37568896.0000\n",
            "Epoch [9580], val_loss: 37118912.0000\n",
            "Epoch [9600], val_loss: 37128588.0000\n",
            "Epoch [9620], val_loss: 37100480.0000\n",
            "Epoch [9640], val_loss: 37891376.0000\n",
            "Epoch [9660], val_loss: 37226272.0000\n",
            "Epoch [9680], val_loss: 37190600.0000\n",
            "Epoch [9700], val_loss: 37645508.0000\n",
            "Epoch [9720], val_loss: 37550384.0000\n",
            "Epoch [9740], val_loss: 38020800.0000\n",
            "Epoch [9760], val_loss: 37203032.0000\n",
            "Epoch [9780], val_loss: 37119064.0000\n",
            "Epoch [9800], val_loss: 37180408.0000\n",
            "Epoch [9820], val_loss: 37186444.0000\n",
            "Epoch [9840], val_loss: 37113684.0000\n",
            "Epoch [9860], val_loss: 37101008.0000\n",
            "Epoch [9880], val_loss: 37102824.0000\n",
            "Epoch [9900], val_loss: 37351596.0000\n",
            "Epoch [9920], val_loss: 37471592.0000\n",
            "Epoch [9940], val_loss: 37255856.0000\n",
            "Epoch [9960], val_loss: 37114960.0000\n",
            "Epoch [9980], val_loss: 37099976.0000\n",
            "Epoch [10000], val_loss: 38216992.0000\n"
          ]
        }
      ],
      "source": [
        "epochs = 10000\n",
        "lr = 1e-4\n",
        "history2 = fit(epochs, lr, model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Yd-JIey9C-mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d625c1-5d94-42ce-dd17-9c1827e53f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20], val_loss: 37269260.0000\n",
            "Epoch [40], val_loss: 37198244.0000\n",
            "Epoch [60], val_loss: 37236560.0000\n",
            "Epoch [80], val_loss: 37224664.0000\n",
            "Epoch [100], val_loss: 37223024.0000\n",
            "Epoch [120], val_loss: 37204072.0000\n",
            "Epoch [140], val_loss: 37231264.0000\n",
            "Epoch [160], val_loss: 37238924.0000\n",
            "Epoch [180], val_loss: 37203132.0000\n",
            "Epoch [200], val_loss: 37198752.0000\n",
            "Epoch [220], val_loss: 37219940.0000\n",
            "Epoch [240], val_loss: 37253692.0000\n",
            "Epoch [260], val_loss: 37190816.0000\n",
            "Epoch [280], val_loss: 37283156.0000\n",
            "Epoch [300], val_loss: 37218224.0000\n",
            "Epoch [320], val_loss: 37196836.0000\n",
            "Epoch [340], val_loss: 37196544.0000\n",
            "Epoch [360], val_loss: 37213308.0000\n",
            "Epoch [380], val_loss: 37199556.0000\n",
            "Epoch [400], val_loss: 37239884.0000\n",
            "Epoch [420], val_loss: 37204600.0000\n",
            "Epoch [440], val_loss: 37265920.0000\n",
            "Epoch [460], val_loss: 37214284.0000\n",
            "Epoch [480], val_loss: 37239860.0000\n",
            "Epoch [500], val_loss: 37198052.0000\n",
            "Epoch [520], val_loss: 37255496.0000\n",
            "Epoch [540], val_loss: 37207408.0000\n",
            "Epoch [560], val_loss: 37202644.0000\n",
            "Epoch [580], val_loss: 37225688.0000\n",
            "Epoch [600], val_loss: 37209064.0000\n",
            "Epoch [620], val_loss: 37213296.0000\n",
            "Epoch [640], val_loss: 37258884.0000\n",
            "Epoch [660], val_loss: 37235136.0000\n",
            "Epoch [680], val_loss: 37175424.0000\n",
            "Epoch [700], val_loss: 37262964.0000\n",
            "Epoch [720], val_loss: 37242916.0000\n",
            "Epoch [740], val_loss: 37213580.0000\n",
            "Epoch [760], val_loss: 37258776.0000\n",
            "Epoch [780], val_loss: 37225512.0000\n",
            "Epoch [800], val_loss: 37234344.0000\n",
            "Epoch [820], val_loss: 37210592.0000\n",
            "Epoch [840], val_loss: 37224472.0000\n",
            "Epoch [860], val_loss: 37210160.0000\n",
            "Epoch [880], val_loss: 37204064.0000\n",
            "Epoch [900], val_loss: 37216064.0000\n",
            "Epoch [920], val_loss: 37223728.0000\n",
            "Epoch [940], val_loss: 37246848.0000\n",
            "Epoch [960], val_loss: 37200608.0000\n",
            "Epoch [980], val_loss: 37202820.0000\n",
            "Epoch [1000], val_loss: 37231176.0000\n",
            "Epoch [1020], val_loss: 37203016.0000\n",
            "Epoch [1040], val_loss: 37200804.0000\n",
            "Epoch [1060], val_loss: 37234868.0000\n",
            "Epoch [1080], val_loss: 37248360.0000\n",
            "Epoch [1100], val_loss: 37188760.0000\n",
            "Epoch [1120], val_loss: 37201276.0000\n",
            "Epoch [1140], val_loss: 37226124.0000\n",
            "Epoch [1160], val_loss: 37203256.0000\n",
            "Epoch [1180], val_loss: 37223016.0000\n",
            "Epoch [1200], val_loss: 37245204.0000\n",
            "Epoch [1220], val_loss: 37190376.0000\n",
            "Epoch [1240], val_loss: 37232928.0000\n",
            "Epoch [1260], val_loss: 37208188.0000\n",
            "Epoch [1280], val_loss: 37212320.0000\n",
            "Epoch [1300], val_loss: 37211436.0000\n",
            "Epoch [1320], val_loss: 37207776.0000\n",
            "Epoch [1340], val_loss: 37219848.0000\n",
            "Epoch [1360], val_loss: 37208780.0000\n",
            "Epoch [1380], val_loss: 37223736.0000\n",
            "Epoch [1400], val_loss: 37197632.0000\n",
            "Epoch [1420], val_loss: 37216840.0000\n",
            "Epoch [1440], val_loss: 37213908.0000\n",
            "Epoch [1460], val_loss: 37209968.0000\n",
            "Epoch [1480], val_loss: 37190444.0000\n",
            "Epoch [1500], val_loss: 37268108.0000\n",
            "Epoch [1520], val_loss: 37232140.0000\n",
            "Epoch [1540], val_loss: 37225508.0000\n",
            "Epoch [1560], val_loss: 37176552.0000\n",
            "Epoch [1580], val_loss: 37227880.0000\n",
            "Epoch [1600], val_loss: 37237120.0000\n",
            "Epoch [1620], val_loss: 37251920.0000\n",
            "Epoch [1640], val_loss: 37208332.0000\n",
            "Epoch [1660], val_loss: 37232240.0000\n",
            "Epoch [1680], val_loss: 37221048.0000\n",
            "Epoch [1700], val_loss: 37196096.0000\n",
            "Epoch [1720], val_loss: 37201260.0000\n",
            "Epoch [1740], val_loss: 37220284.0000\n",
            "Epoch [1760], val_loss: 37192720.0000\n",
            "Epoch [1780], val_loss: 37228228.0000\n",
            "Epoch [1800], val_loss: 37213904.0000\n",
            "Epoch [1820], val_loss: 37208488.0000\n",
            "Epoch [1840], val_loss: 37193016.0000\n",
            "Epoch [1860], val_loss: 37191028.0000\n",
            "Epoch [1880], val_loss: 37248504.0000\n",
            "Epoch [1900], val_loss: 37264528.0000\n",
            "Epoch [1920], val_loss: 37208120.0000\n",
            "Epoch [1940], val_loss: 37210548.0000\n",
            "Epoch [1960], val_loss: 37204816.0000\n",
            "Epoch [1980], val_loss: 37233576.0000\n",
            "Epoch [2000], val_loss: 37248344.0000\n"
          ]
        }
      ],
      "source": [
        "epochs = 2000\n",
        "lr = 1e-5\n",
        "history3 = fit(epochs, lr, model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "W_1kmws7C-mp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c13ed24c-ed12-42bb-e436-5ce037468b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20], val_loss: 37242444.0000\n",
            "Epoch [40], val_loss: 37237264.0000\n",
            "Epoch [60], val_loss: 37233420.0000\n",
            "Epoch [80], val_loss: 37230196.0000\n",
            "Epoch [100], val_loss: 37227768.0000\n",
            "Epoch [120], val_loss: 37225552.0000\n",
            "Epoch [140], val_loss: 37223452.0000\n",
            "Epoch [160], val_loss: 37222088.0000\n",
            "Epoch [180], val_loss: 37220792.0000\n",
            "Epoch [200], val_loss: 37219784.0000\n",
            "Epoch [220], val_loss: 37219112.0000\n",
            "Epoch [240], val_loss: 37218392.0000\n",
            "Epoch [260], val_loss: 37217896.0000\n",
            "Epoch [280], val_loss: 37217280.0000\n",
            "Epoch [300], val_loss: 37216852.0000\n",
            "Epoch [320], val_loss: 37216532.0000\n",
            "Epoch [340], val_loss: 37216292.0000\n",
            "Epoch [360], val_loss: 37216384.0000\n",
            "Epoch [380], val_loss: 37216160.0000\n",
            "Epoch [400], val_loss: 37216384.0000\n",
            "Epoch [420], val_loss: 37216448.0000\n",
            "Epoch [440], val_loss: 37216532.0000\n",
            "Epoch [460], val_loss: 37216040.0000\n",
            "Epoch [480], val_loss: 37216144.0000\n",
            "Epoch [500], val_loss: 37216044.0000\n",
            "Epoch [520], val_loss: 37215648.0000\n",
            "Epoch [540], val_loss: 37215540.0000\n",
            "Epoch [560], val_loss: 37215320.0000\n",
            "Epoch [580], val_loss: 37215440.0000\n",
            "Epoch [600], val_loss: 37215676.0000\n",
            "Epoch [620], val_loss: 37215576.0000\n",
            "Epoch [640], val_loss: 37215404.0000\n",
            "Epoch [660], val_loss: 37215284.0000\n",
            "Epoch [680], val_loss: 37215456.0000\n",
            "Epoch [700], val_loss: 37215460.0000\n",
            "Epoch [720], val_loss: 37215336.0000\n",
            "Epoch [740], val_loss: 37215344.0000\n",
            "Epoch [760], val_loss: 37215256.0000\n",
            "Epoch [780], val_loss: 37215564.0000\n",
            "Epoch [800], val_loss: 37215636.0000\n",
            "Epoch [820], val_loss: 37215620.0000\n",
            "Epoch [840], val_loss: 37215480.0000\n",
            "Epoch [860], val_loss: 37215416.0000\n",
            "Epoch [880], val_loss: 37215360.0000\n",
            "Epoch [900], val_loss: 37215192.0000\n",
            "Epoch [920], val_loss: 37215008.0000\n",
            "Epoch [940], val_loss: 37215184.0000\n",
            "Epoch [960], val_loss: 37215064.0000\n",
            "Epoch [980], val_loss: 37214828.0000\n",
            "Epoch [1000], val_loss: 37215024.0000\n"
          ]
        }
      ],
      "source": [
        "epochs = 1000\n",
        "lr = 1e-7\n",
        "history4 = fit(epochs, lr, model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "IFBByrrqC-mq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7082a0be-6959-454d-a310-81fb5a38e157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20], val_loss: 37151192.0000\n",
            "Epoch [40], val_loss: 37236176.0000\n",
            "Epoch [60], val_loss: 38443176.0000\n",
            "Epoch [80], val_loss: 37116824.0000\n",
            "Epoch [100], val_loss: 37299316.0000\n",
            "Epoch [120], val_loss: 37231600.0000\n",
            "Epoch [140], val_loss: 37255148.0000\n",
            "Epoch [160], val_loss: 37717916.0000\n",
            "Epoch [180], val_loss: 37726900.0000\n",
            "Epoch [200], val_loss: 37478780.0000\n",
            "Epoch [220], val_loss: 37231728.0000\n",
            "Epoch [240], val_loss: 37315444.0000\n",
            "Epoch [260], val_loss: 37256888.0000\n",
            "Epoch [280], val_loss: 37102604.0000\n",
            "Epoch [300], val_loss: 37227480.0000\n",
            "Epoch [320], val_loss: 37301896.0000\n",
            "Epoch [340], val_loss: 37208072.0000\n",
            "Epoch [360], val_loss: 37613436.0000\n",
            "Epoch [380], val_loss: 37480276.0000\n",
            "Epoch [400], val_loss: 38753616.0000\n",
            "Epoch [420], val_loss: 37967892.0000\n",
            "Epoch [440], val_loss: 37188940.0000\n",
            "Epoch [460], val_loss: 38111472.0000\n",
            "Epoch [480], val_loss: 37106800.0000\n",
            "Epoch [500], val_loss: 37254012.0000\n",
            "Epoch [520], val_loss: 37137352.0000\n",
            "Epoch [540], val_loss: 37381368.0000\n",
            "Epoch [560], val_loss: 37187872.0000\n",
            "Epoch [580], val_loss: 37375828.0000\n",
            "Epoch [600], val_loss: 37487788.0000\n",
            "Epoch [620], val_loss: 37572496.0000\n",
            "Epoch [640], val_loss: 37602032.0000\n",
            "Epoch [660], val_loss: 37889856.0000\n",
            "Epoch [680], val_loss: 37235168.0000\n",
            "Epoch [700], val_loss: 37368460.0000\n",
            "Epoch [720], val_loss: 37149004.0000\n",
            "Epoch [740], val_loss: 37154300.0000\n",
            "Epoch [760], val_loss: 37340544.0000\n",
            "Epoch [780], val_loss: 37211000.0000\n",
            "Epoch [800], val_loss: 37454688.0000\n",
            "Epoch [820], val_loss: 37133700.0000\n",
            "Epoch [840], val_loss: 37199360.0000\n",
            "Epoch [860], val_loss: 37132336.0000\n",
            "Epoch [880], val_loss: 37971908.0000\n",
            "Epoch [900], val_loss: 37242000.0000\n",
            "Epoch [920], val_loss: 37426244.0000\n",
            "Epoch [940], val_loss: 37109316.0000\n",
            "Epoch [960], val_loss: 37290924.0000\n",
            "Epoch [980], val_loss: 37386648.0000\n",
            "Epoch [1000], val_loss: 37853824.0000\n",
            "Epoch [1020], val_loss: 38251228.0000\n",
            "Epoch [1040], val_loss: 37591892.0000\n",
            "Epoch [1060], val_loss: 37503168.0000\n",
            "Epoch [1080], val_loss: 37213156.0000\n",
            "Epoch [1100], val_loss: 37144460.0000\n",
            "Epoch [1120], val_loss: 38952468.0000\n",
            "Epoch [1140], val_loss: 37678468.0000\n",
            "Epoch [1160], val_loss: 37142080.0000\n",
            "Epoch [1180], val_loss: 37220176.0000\n",
            "Epoch [1200], val_loss: 37173464.0000\n",
            "Epoch [1220], val_loss: 37101400.0000\n",
            "Epoch [1240], val_loss: 38158620.0000\n",
            "Epoch [1260], val_loss: 37549980.0000\n",
            "Epoch [1280], val_loss: 37129380.0000\n",
            "Epoch [1300], val_loss: 37273108.0000\n",
            "Epoch [1320], val_loss: 37159792.0000\n",
            "Epoch [1340], val_loss: 37102208.0000\n",
            "Epoch [1360], val_loss: 37111508.0000\n",
            "Epoch [1380], val_loss: 37141560.0000\n",
            "Epoch [1400], val_loss: 37181248.0000\n",
            "Epoch [1420], val_loss: 37564832.0000\n",
            "Epoch [1440], val_loss: 37118056.0000\n",
            "Epoch [1460], val_loss: 38194656.0000\n",
            "Epoch [1480], val_loss: 38077688.0000\n",
            "Epoch [1500], val_loss: 37863044.0000\n",
            "Epoch [1520], val_loss: 37561864.0000\n",
            "Epoch [1540], val_loss: 37294304.0000\n",
            "Epoch [1560], val_loss: 37454764.0000\n",
            "Epoch [1580], val_loss: 37700380.0000\n",
            "Epoch [1600], val_loss: 37107888.0000\n",
            "Epoch [1620], val_loss: 37102864.0000\n",
            "Epoch [1640], val_loss: 37153124.0000\n",
            "Epoch [1660], val_loss: 37870604.0000\n",
            "Epoch [1680], val_loss: 37995536.0000\n",
            "Epoch [1700], val_loss: 37807956.0000\n",
            "Epoch [1720], val_loss: 37914376.0000\n",
            "Epoch [1740], val_loss: 37207336.0000\n",
            "Epoch [1760], val_loss: 37179328.0000\n",
            "Epoch [1780], val_loss: 37981716.0000\n",
            "Epoch [1800], val_loss: 37110904.0000\n",
            "Epoch [1820], val_loss: 37747036.0000\n",
            "Epoch [1840], val_loss: 37104232.0000\n",
            "Epoch [1860], val_loss: 38160392.0000\n",
            "Epoch [1880], val_loss: 37114056.0000\n",
            "Epoch [1900], val_loss: 37103132.0000\n",
            "Epoch [1920], val_loss: 38824492.0000\n",
            "Epoch [1940], val_loss: 37110792.0000\n",
            "Epoch [1960], val_loss: 37805592.0000\n",
            "Epoch [1980], val_loss: 37430148.0000\n",
            "Epoch [2000], val_loss: 37367880.0000\n",
            "Epoch [2020], val_loss: 38453504.0000\n",
            "Epoch [2040], val_loss: 37106848.0000\n",
            "Epoch [2060], val_loss: 37378124.0000\n",
            "Epoch [2080], val_loss: 37268040.0000\n",
            "Epoch [2100], val_loss: 37115688.0000\n",
            "Epoch [2120], val_loss: 37237008.0000\n",
            "Epoch [2140], val_loss: 37761536.0000\n",
            "Epoch [2160], val_loss: 37533296.0000\n",
            "Epoch [2180], val_loss: 37116512.0000\n",
            "Epoch [2200], val_loss: 37116056.0000\n",
            "Epoch [2220], val_loss: 37658632.0000\n",
            "Epoch [2240], val_loss: 37494512.0000\n",
            "Epoch [2260], val_loss: 37106596.0000\n",
            "Epoch [2280], val_loss: 37230512.0000\n",
            "Epoch [2300], val_loss: 37115508.0000\n",
            "Epoch [2320], val_loss: 38193472.0000\n",
            "Epoch [2340], val_loss: 37122512.0000\n",
            "Epoch [2360], val_loss: 37128820.0000\n",
            "Epoch [2380], val_loss: 37131044.0000\n",
            "Epoch [2400], val_loss: 37130608.0000\n",
            "Epoch [2420], val_loss: 37244560.0000\n",
            "Epoch [2440], val_loss: 38471140.0000\n",
            "Epoch [2460], val_loss: 37119976.0000\n",
            "Epoch [2480], val_loss: 37136720.0000\n",
            "Epoch [2500], val_loss: 38249544.0000\n",
            "Epoch [2520], val_loss: 37130948.0000\n",
            "Epoch [2540], val_loss: 37132000.0000\n",
            "Epoch [2560], val_loss: 37119368.0000\n",
            "Epoch [2580], val_loss: 37193392.0000\n",
            "Epoch [2600], val_loss: 38246696.0000\n",
            "Epoch [2620], val_loss: 38187424.0000\n",
            "Epoch [2640], val_loss: 37116952.0000\n",
            "Epoch [2660], val_loss: 37323772.0000\n",
            "Epoch [2680], val_loss: 37158968.0000\n",
            "Epoch [2700], val_loss: 37165696.0000\n",
            "Epoch [2720], val_loss: 37705472.0000\n",
            "Epoch [2740], val_loss: 37217328.0000\n",
            "Epoch [2760], val_loss: 37201256.0000\n",
            "Epoch [2780], val_loss: 37167392.0000\n",
            "Epoch [2800], val_loss: 37289368.0000\n",
            "Epoch [2820], val_loss: 37131724.0000\n",
            "Epoch [2840], val_loss: 37254144.0000\n",
            "Epoch [2860], val_loss: 37311544.0000\n",
            "Epoch [2880], val_loss: 37148396.0000\n",
            "Epoch [2900], val_loss: 37525936.0000\n",
            "Epoch [2920], val_loss: 37555416.0000\n",
            "Epoch [2940], val_loss: 37122856.0000\n",
            "Epoch [2960], val_loss: 37388616.0000\n",
            "Epoch [2980], val_loss: 37133656.0000\n",
            "Epoch [3000], val_loss: 37123944.0000\n",
            "Epoch [3020], val_loss: 37392568.0000\n",
            "Epoch [3040], val_loss: 37320032.0000\n",
            "Epoch [3060], val_loss: 37364780.0000\n",
            "Epoch [3080], val_loss: 37168008.0000\n",
            "Epoch [3100], val_loss: 37395168.0000\n",
            "Epoch [3120], val_loss: 37121928.0000\n",
            "Epoch [3140], val_loss: 37308024.0000\n",
            "Epoch [3160], val_loss: 37354400.0000\n",
            "Epoch [3180], val_loss: 37119848.0000\n",
            "Epoch [3200], val_loss: 37412420.0000\n",
            "Epoch [3220], val_loss: 37540304.0000\n",
            "Epoch [3240], val_loss: 38017728.0000\n",
            "Epoch [3260], val_loss: 37240792.0000\n",
            "Epoch [3280], val_loss: 37174932.0000\n",
            "Epoch [3300], val_loss: 37365768.0000\n",
            "Epoch [3320], val_loss: 37824808.0000\n",
            "Epoch [3340], val_loss: 37147288.0000\n",
            "Epoch [3360], val_loss: 37916896.0000\n",
            "Epoch [3380], val_loss: 37148072.0000\n",
            "Epoch [3400], val_loss: 37475344.0000\n",
            "Epoch [3420], val_loss: 37528684.0000\n",
            "Epoch [3440], val_loss: 37118120.0000\n",
            "Epoch [3460], val_loss: 37954964.0000\n",
            "Epoch [3480], val_loss: 37128696.0000\n",
            "Epoch [3500], val_loss: 37433992.0000\n",
            "Epoch [3520], val_loss: 37983568.0000\n",
            "Epoch [3540], val_loss: 37376248.0000\n",
            "Epoch [3560], val_loss: 37118352.0000\n",
            "Epoch [3580], val_loss: 37199464.0000\n",
            "Epoch [3600], val_loss: 37195004.0000\n",
            "Epoch [3620], val_loss: 37928300.0000\n",
            "Epoch [3640], val_loss: 37804400.0000\n",
            "Epoch [3660], val_loss: 37666536.0000\n",
            "Epoch [3680], val_loss: 37175180.0000\n",
            "Epoch [3700], val_loss: 37821920.0000\n",
            "Epoch [3720], val_loss: 37143732.0000\n",
            "Epoch [3740], val_loss: 37794392.0000\n",
            "Epoch [3760], val_loss: 37302060.0000\n",
            "Epoch [3780], val_loss: 37444972.0000\n",
            "Epoch [3800], val_loss: 37203912.0000\n",
            "Epoch [3820], val_loss: 37470796.0000\n",
            "Epoch [3840], val_loss: 37699304.0000\n",
            "Epoch [3860], val_loss: 37453620.0000\n",
            "Epoch [3880], val_loss: 37152868.0000\n",
            "Epoch [3900], val_loss: 37191100.0000\n",
            "Epoch [3920], val_loss: 37503096.0000\n",
            "Epoch [3940], val_loss: 37248240.0000\n",
            "Epoch [3960], val_loss: 37570704.0000\n",
            "Epoch [3980], val_loss: 37174264.0000\n",
            "Epoch [4000], val_loss: 37215356.0000\n",
            "Epoch [4020], val_loss: 37447184.0000\n",
            "Epoch [4040], val_loss: 37140516.0000\n",
            "Epoch [4060], val_loss: 37340556.0000\n",
            "Epoch [4080], val_loss: 38094992.0000\n",
            "Epoch [4100], val_loss: 37130608.0000\n",
            "Epoch [4120], val_loss: 37179668.0000\n",
            "Epoch [4140], val_loss: 37245696.0000\n",
            "Epoch [4160], val_loss: 37134836.0000\n",
            "Epoch [4180], val_loss: 37503176.0000\n",
            "Epoch [4200], val_loss: 37201256.0000\n",
            "Epoch [4220], val_loss: 37582816.0000\n",
            "Epoch [4240], val_loss: 38498392.0000\n",
            "Epoch [4260], val_loss: 37383436.0000\n",
            "Epoch [4280], val_loss: 37404160.0000\n",
            "Epoch [4300], val_loss: 38437456.0000\n",
            "Epoch [4320], val_loss: 37266836.0000\n",
            "Epoch [4340], val_loss: 37126440.0000\n",
            "Epoch [4360], val_loss: 37303412.0000\n",
            "Epoch [4380], val_loss: 37383528.0000\n",
            "Epoch [4400], val_loss: 37159312.0000\n",
            "Epoch [4420], val_loss: 37373740.0000\n",
            "Epoch [4440], val_loss: 37300952.0000\n",
            "Epoch [4460], val_loss: 37476172.0000\n",
            "Epoch [4480], val_loss: 37282436.0000\n",
            "Epoch [4500], val_loss: 37151412.0000\n",
            "Epoch [4520], val_loss: 37472864.0000\n",
            "Epoch [4540], val_loss: 37157808.0000\n",
            "Epoch [4560], val_loss: 37435928.0000\n",
            "Epoch [4580], val_loss: 38640680.0000\n",
            "Epoch [4600], val_loss: 37123980.0000\n",
            "Epoch [4620], val_loss: 37145496.0000\n",
            "Epoch [4640], val_loss: 37164280.0000\n",
            "Epoch [4660], val_loss: 37139212.0000\n",
            "Epoch [4680], val_loss: 37223284.0000\n",
            "Epoch [4700], val_loss: 37204296.0000\n",
            "Epoch [4720], val_loss: 37367064.0000\n",
            "Epoch [4740], val_loss: 37122220.0000\n",
            "Epoch [4760], val_loss: 37709096.0000\n",
            "Epoch [4780], val_loss: 37581368.0000\n",
            "Epoch [4800], val_loss: 37157496.0000\n",
            "Epoch [4820], val_loss: 37180320.0000\n",
            "Epoch [4840], val_loss: 37165128.0000\n",
            "Epoch [4860], val_loss: 37227848.0000\n",
            "Epoch [4880], val_loss: 37264816.0000\n",
            "Epoch [4900], val_loss: 37224292.0000\n",
            "Epoch [4920], val_loss: 37436308.0000\n",
            "Epoch [4940], val_loss: 37421664.0000\n",
            "Epoch [4960], val_loss: 37405072.0000\n",
            "Epoch [4980], val_loss: 37674568.0000\n",
            "Epoch [5000], val_loss: 37140460.0000\n",
            "Epoch [5020], val_loss: 38935676.0000\n",
            "Epoch [5040], val_loss: 37300696.0000\n",
            "Epoch [5060], val_loss: 37128292.0000\n",
            "Epoch [5080], val_loss: 37138964.0000\n",
            "Epoch [5100], val_loss: 37198528.0000\n",
            "Epoch [5120], val_loss: 37978548.0000\n",
            "Epoch [5140], val_loss: 37159584.0000\n",
            "Epoch [5160], val_loss: 37327972.0000\n",
            "Epoch [5180], val_loss: 37134404.0000\n",
            "Epoch [5200], val_loss: 38565928.0000\n",
            "Epoch [5220], val_loss: 37129080.0000\n",
            "Epoch [5240], val_loss: 37215024.0000\n",
            "Epoch [5260], val_loss: 38357560.0000\n",
            "Epoch [5280], val_loss: 37144832.0000\n",
            "Epoch [5300], val_loss: 38312956.0000\n",
            "Epoch [5320], val_loss: 37350808.0000\n",
            "Epoch [5340], val_loss: 37212152.0000\n",
            "Epoch [5360], val_loss: 37162944.0000\n",
            "Epoch [5380], val_loss: 37144724.0000\n",
            "Epoch [5400], val_loss: 37452668.0000\n",
            "Epoch [5420], val_loss: 37204376.0000\n",
            "Epoch [5440], val_loss: 37137628.0000\n",
            "Epoch [5460], val_loss: 37506316.0000\n",
            "Epoch [5480], val_loss: 38351024.0000\n",
            "Epoch [5500], val_loss: 37140004.0000\n",
            "Epoch [5520], val_loss: 37199060.0000\n",
            "Epoch [5540], val_loss: 37848548.0000\n",
            "Epoch [5560], val_loss: 37203024.0000\n",
            "Epoch [5580], val_loss: 37616248.0000\n",
            "Epoch [5600], val_loss: 37419552.0000\n",
            "Epoch [5620], val_loss: 37132172.0000\n",
            "Epoch [5640], val_loss: 37937176.0000\n",
            "Epoch [5660], val_loss: 37582768.0000\n",
            "Epoch [5680], val_loss: 37130972.0000\n",
            "Epoch [5700], val_loss: 38018596.0000\n",
            "Epoch [5720], val_loss: 38196752.0000\n",
            "Epoch [5740], val_loss: 37221992.0000\n",
            "Epoch [5760], val_loss: 37452728.0000\n",
            "Epoch [5780], val_loss: 37166280.0000\n",
            "Epoch [5800], val_loss: 37226944.0000\n",
            "Epoch [5820], val_loss: 37782636.0000\n",
            "Epoch [5840], val_loss: 38137816.0000\n",
            "Epoch [5860], val_loss: 37146168.0000\n",
            "Epoch [5880], val_loss: 37325632.0000\n",
            "Epoch [5900], val_loss: 38229168.0000\n",
            "Epoch [5920], val_loss: 37614340.0000\n",
            "Epoch [5940], val_loss: 37398940.0000\n",
            "Epoch [5960], val_loss: 37595332.0000\n",
            "Epoch [5980], val_loss: 37536580.0000\n",
            "Epoch [6000], val_loss: 38205224.0000\n",
            "Epoch [6020], val_loss: 37831440.0000\n",
            "Epoch [6040], val_loss: 37135792.0000\n",
            "Epoch [6060], val_loss: 37437008.0000\n",
            "Epoch [6080], val_loss: 37152768.0000\n",
            "Epoch [6100], val_loss: 38000488.0000\n",
            "Epoch [6120], val_loss: 37834500.0000\n",
            "Epoch [6140], val_loss: 37214864.0000\n",
            "Epoch [6160], val_loss: 37334404.0000\n",
            "Epoch [6180], val_loss: 37137048.0000\n",
            "Epoch [6200], val_loss: 37416128.0000\n",
            "Epoch [6220], val_loss: 37183096.0000\n",
            "Epoch [6240], val_loss: 37144184.0000\n",
            "Epoch [6260], val_loss: 37241940.0000\n",
            "Epoch [6280], val_loss: 37840684.0000\n",
            "Epoch [6300], val_loss: 38067820.0000\n",
            "Epoch [6320], val_loss: 37186028.0000\n",
            "Epoch [6340], val_loss: 37342720.0000\n",
            "Epoch [6360], val_loss: 37649172.0000\n",
            "Epoch [6380], val_loss: 37387540.0000\n",
            "Epoch [6400], val_loss: 37183120.0000\n",
            "Epoch [6420], val_loss: 37136952.0000\n",
            "Epoch [6440], val_loss: 38275528.0000\n",
            "Epoch [6460], val_loss: 39132464.0000\n",
            "Epoch [6480], val_loss: 37187536.0000\n",
            "Epoch [6500], val_loss: 37179076.0000\n",
            "Epoch [6520], val_loss: 37250704.0000\n",
            "Epoch [6540], val_loss: 37617160.0000\n",
            "Epoch [6560], val_loss: 39444632.0000\n",
            "Epoch [6580], val_loss: 37355632.0000\n",
            "Epoch [6600], val_loss: 37178232.0000\n",
            "Epoch [6620], val_loss: 37499472.0000\n",
            "Epoch [6640], val_loss: 37534648.0000\n",
            "Epoch [6660], val_loss: 37642368.0000\n",
            "Epoch [6680], val_loss: 38239120.0000\n",
            "Epoch [6700], val_loss: 37544428.0000\n",
            "Epoch [6720], val_loss: 37922924.0000\n",
            "Epoch [6740], val_loss: 37152064.0000\n",
            "Epoch [6760], val_loss: 37290216.0000\n",
            "Epoch [6780], val_loss: 38017752.0000\n",
            "Epoch [6800], val_loss: 37180424.0000\n",
            "Epoch [6820], val_loss: 37517652.0000\n",
            "Epoch [6840], val_loss: 37819096.0000\n",
            "Epoch [6860], val_loss: 37441760.0000\n",
            "Epoch [6880], val_loss: 37593992.0000\n",
            "Epoch [6900], val_loss: 39276912.0000\n",
            "Epoch [6920], val_loss: 37171128.0000\n",
            "Epoch [6940], val_loss: 37939888.0000\n",
            "Epoch [6960], val_loss: 37451040.0000\n",
            "Epoch [6980], val_loss: 37270840.0000\n",
            "Epoch [7000], val_loss: 37572272.0000\n",
            "Epoch [7020], val_loss: 37166212.0000\n",
            "Epoch [7040], val_loss: 37191224.0000\n",
            "Epoch [7060], val_loss: 37855700.0000\n",
            "Epoch [7080], val_loss: 39485788.0000\n",
            "Epoch [7100], val_loss: 37247568.0000\n",
            "Epoch [7120], val_loss: 37466104.0000\n",
            "Epoch [7140], val_loss: 37266572.0000\n",
            "Epoch [7160], val_loss: 37155144.0000\n",
            "Epoch [7180], val_loss: 37637864.0000\n",
            "Epoch [7200], val_loss: 37168304.0000\n",
            "Epoch [7220], val_loss: 37155472.0000\n",
            "Epoch [7240], val_loss: 37556616.0000\n",
            "Epoch [7260], val_loss: 37354912.0000\n",
            "Epoch [7280], val_loss: 37509708.0000\n",
            "Epoch [7300], val_loss: 37458408.0000\n",
            "Epoch [7320], val_loss: 37338240.0000\n",
            "Epoch [7340], val_loss: 37325584.0000\n",
            "Epoch [7360], val_loss: 37140496.0000\n",
            "Epoch [7380], val_loss: 37163992.0000\n",
            "Epoch [7400], val_loss: 37251688.0000\n",
            "Epoch [7420], val_loss: 37732988.0000\n",
            "Epoch [7440], val_loss: 37736476.0000\n",
            "Epoch [7460], val_loss: 37259608.0000\n",
            "Epoch [7480], val_loss: 37503728.0000\n",
            "Epoch [7500], val_loss: 37195220.0000\n",
            "Epoch [7520], val_loss: 37638028.0000\n",
            "Epoch [7540], val_loss: 37557272.0000\n",
            "Epoch [7560], val_loss: 38784380.0000\n",
            "Epoch [7580], val_loss: 37146612.0000\n",
            "Epoch [7600], val_loss: 37177788.0000\n",
            "Epoch [7620], val_loss: 37427936.0000\n",
            "Epoch [7640], val_loss: 37342344.0000\n",
            "Epoch [7660], val_loss: 38172272.0000\n",
            "Epoch [7680], val_loss: 37717256.0000\n",
            "Epoch [7700], val_loss: 37299200.0000\n",
            "Epoch [7720], val_loss: 38078808.0000\n",
            "Epoch [7740], val_loss: 37282812.0000\n",
            "Epoch [7760], val_loss: 37512060.0000\n",
            "Epoch [7780], val_loss: 37150796.0000\n",
            "Epoch [7800], val_loss: 37403296.0000\n",
            "Epoch [7820], val_loss: 37236172.0000\n",
            "Epoch [7840], val_loss: 37219992.0000\n",
            "Epoch [7860], val_loss: 37427012.0000\n",
            "Epoch [7880], val_loss: 37219704.0000\n",
            "Epoch [7900], val_loss: 37971032.0000\n",
            "Epoch [7920], val_loss: 37230192.0000\n",
            "Epoch [7940], val_loss: 37159156.0000\n",
            "Epoch [7960], val_loss: 38531116.0000\n",
            "Epoch [7980], val_loss: 37282544.0000\n",
            "Epoch [8000], val_loss: 37253952.0000\n",
            "Epoch [8020], val_loss: 37228040.0000\n",
            "Epoch [8040], val_loss: 37151600.0000\n",
            "Epoch [8060], val_loss: 37464904.0000\n",
            "Epoch [8080], val_loss: 37164292.0000\n",
            "Epoch [8100], val_loss: 37566064.0000\n",
            "Epoch [8120], val_loss: 37157464.0000\n",
            "Epoch [8140], val_loss: 37291724.0000\n",
            "Epoch [8160], val_loss: 37560288.0000\n",
            "Epoch [8180], val_loss: 37470748.0000\n",
            "Epoch [8200], val_loss: 37504532.0000\n",
            "Epoch [8220], val_loss: 37157812.0000\n",
            "Epoch [8240], val_loss: 37625256.0000\n",
            "Epoch [8260], val_loss: 37327904.0000\n",
            "Epoch [8280], val_loss: 37855912.0000\n",
            "Epoch [8300], val_loss: 37210020.0000\n",
            "Epoch [8320], val_loss: 37165732.0000\n",
            "Epoch [8340], val_loss: 37160464.0000\n",
            "Epoch [8360], val_loss: 37880548.0000\n",
            "Epoch [8380], val_loss: 37157976.0000\n",
            "Epoch [8400], val_loss: 38417924.0000\n",
            "Epoch [8420], val_loss: 37496920.0000\n",
            "Epoch [8440], val_loss: 37208780.0000\n",
            "Epoch [8460], val_loss: 37235448.0000\n",
            "Epoch [8480], val_loss: 37484264.0000\n",
            "Epoch [8500], val_loss: 37247308.0000\n",
            "Epoch [8520], val_loss: 37500724.0000\n",
            "Epoch [8540], val_loss: 37797804.0000\n",
            "Epoch [8560], val_loss: 37333432.0000\n",
            "Epoch [8580], val_loss: 37269392.0000\n",
            "Epoch [8600], val_loss: 37499552.0000\n",
            "Epoch [8620], val_loss: 38406720.0000\n",
            "Epoch [8640], val_loss: 37695904.0000\n",
            "Epoch [8660], val_loss: 37422224.0000\n",
            "Epoch [8680], val_loss: 37152396.0000\n",
            "Epoch [8700], val_loss: 37157040.0000\n",
            "Epoch [8720], val_loss: 37227812.0000\n",
            "Epoch [8740], val_loss: 37442604.0000\n",
            "Epoch [8760], val_loss: 37862084.0000\n",
            "Epoch [8780], val_loss: 37553400.0000\n",
            "Epoch [8800], val_loss: 37157312.0000\n",
            "Epoch [8820], val_loss: 37348872.0000\n",
            "Epoch [8840], val_loss: 37169664.0000\n",
            "Epoch [8860], val_loss: 37181048.0000\n",
            "Epoch [8880], val_loss: 37183388.0000\n",
            "Epoch [8900], val_loss: 37310188.0000\n",
            "Epoch [8920], val_loss: 37755260.0000\n",
            "Epoch [8940], val_loss: 37576548.0000\n",
            "Epoch [8960], val_loss: 37377224.0000\n",
            "Epoch [8980], val_loss: 37284772.0000\n",
            "Epoch [9000], val_loss: 37164008.0000\n",
            "Epoch [9020], val_loss: 37154592.0000\n",
            "Epoch [9040], val_loss: 37203244.0000\n",
            "Epoch [9060], val_loss: 37160524.0000\n",
            "Epoch [9080], val_loss: 37285532.0000\n",
            "Epoch [9100], val_loss: 37223800.0000\n",
            "Epoch [9120], val_loss: 37167264.0000\n",
            "Epoch [9140], val_loss: 37236824.0000\n",
            "Epoch [9160], val_loss: 37665356.0000\n",
            "Epoch [9180], val_loss: 37413228.0000\n",
            "Epoch [9200], val_loss: 37170180.0000\n",
            "Epoch [9220], val_loss: 37236420.0000\n",
            "Epoch [9240], val_loss: 37175440.0000\n",
            "Epoch [9260], val_loss: 37447980.0000\n",
            "Epoch [9280], val_loss: 37949720.0000\n",
            "Epoch [9300], val_loss: 37319292.0000\n",
            "Epoch [9320], val_loss: 37159272.0000\n",
            "Epoch [9340], val_loss: 37214380.0000\n",
            "Epoch [9360], val_loss: 37190872.0000\n",
            "Epoch [9380], val_loss: 37586468.0000\n",
            "Epoch [9400], val_loss: 37276448.0000\n",
            "Epoch [9420], val_loss: 37755144.0000\n",
            "Epoch [9440], val_loss: 37288208.0000\n",
            "Epoch [9460], val_loss: 37158860.0000\n",
            "Epoch [9480], val_loss: 37570532.0000\n",
            "Epoch [9500], val_loss: 37291788.0000\n",
            "Epoch [9520], val_loss: 38812172.0000\n",
            "Epoch [9540], val_loss: 37243892.0000\n",
            "Epoch [9560], val_loss: 37193768.0000\n",
            "Epoch [9580], val_loss: 37341268.0000\n",
            "Epoch [9600], val_loss: 37193344.0000\n",
            "Epoch [9620], val_loss: 37550036.0000\n",
            "Epoch [9640], val_loss: 37545724.0000\n",
            "Epoch [9660], val_loss: 37197076.0000\n",
            "Epoch [9680], val_loss: 37210388.0000\n",
            "Epoch [9700], val_loss: 37158392.0000\n",
            "Epoch [9720], val_loss: 37218464.0000\n",
            "Epoch [9740], val_loss: 37272516.0000\n",
            "Epoch [9760], val_loss: 37947472.0000\n",
            "Epoch [9780], val_loss: 37315260.0000\n",
            "Epoch [9800], val_loss: 37201400.0000\n",
            "Epoch [9820], val_loss: 37449152.0000\n",
            "Epoch [9840], val_loss: 37540720.0000\n",
            "Epoch [9860], val_loss: 37263300.0000\n",
            "Epoch [9880], val_loss: 37425080.0000\n",
            "Epoch [9900], val_loss: 37782056.0000\n",
            "Epoch [9920], val_loss: 37357928.0000\n",
            "Epoch [9940], val_loss: 37187572.0000\n",
            "Epoch [9960], val_loss: 37282520.0000\n",
            "Epoch [9980], val_loss: 38408844.0000\n",
            "Epoch [10000], val_loss: 37299528.0000\n"
          ]
        }
      ],
      "source": [
        "epochs = 10000\n",
        "lr = 1e-4\n",
        "history5 = fit(epochs, lr, model, train_loader, val_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49o9lShmC-mq"
      },
      "source": [
        "**Q12: What is the final validation loss of your model?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "10Bz1lajC-mq"
      },
      "outputs": [],
      "source": [
        "val_loss = 37299528.000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOKZrl_QC-mq"
      },
      "source": [
        "Let's log the final validation loss to Jovian and commit the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "ZMTGZEsJC-mr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93f4d8cb-f53f-4c22-b651-3db753632549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[jovian] Please enter your API key ( from https://jovian.com/ ):\u001b[0m\n",
            "API KEY: \n",
            "[jovian] Metrics logged.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "jovian.log_metrics(val_loss=val_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Us4LsnzrC-ms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b44f2e4-d25c-4f03-b6af-009248ae2ff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[jovian] Detected Colab notebook...\u001b[0m\n",
            "[jovian] jovian.commit() is no longer required on Google Colab. If you ran this notebook from Jovian, \n",
            "then just save this file in Colab using Ctrl+S/Cmd+S and it will be updated on Jovian. \n",
            "Also, you can also delete this cell, it's no longer necessary.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "jovian.commit(project=project_name, environment=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Apn9MV1CC-ms"
      },
      "source": [
        "Now scroll back up, re-initialize the model, and try different set of values for batch size, number of epochs, learning rate etc. Commit each experiment and use the \"Compare\" and \"View Diff\" options on Jovian to compare the different results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O62Qd-W1C-mt"
      },
      "source": [
        "## Step 5: Make predictions using the trained model\n",
        "\n",
        "**Q13: Complete the following function definition to make predictions on a single input**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "CxklDsBnC-mu"
      },
      "outputs": [],
      "source": [
        "def predict_single(input, target, model):\n",
        "    inputs = input.unsqueeze(0)\n",
        "    predictions = model(inputs)                # fill this\n",
        "    prediction = predictions[0].detach()\n",
        "    print(\"Input:\", input)\n",
        "    print(\"Target:\", target)\n",
        "    print(\"Prediction:\", prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "LpKL2rv1C-mu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422e92ec-8ddb-42f7-f968-111bb306b055"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([53.0000,  0.0000, 29.5260,  0.0000,  0.0000])\n",
            "Target: tensor([10148.5283])\n",
            "Prediction: tensor([10098.7363])\n"
          ]
        }
      ],
      "source": [
        "input, target = val_ds[0]\n",
        "predict_single(input, target, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "RwWUXf-sC-mv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ca91a6-f3b6-46fc-efe9-d5b14d75dc49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([32.0000,  0.0000, 32.1123,  0.0000,  0.0000])\n",
            "Target: tensor([3893.4663])\n",
            "Prediction: tensor([5497.8340])\n"
          ]
        }
      ],
      "source": [
        "input, target = val_ds[10]\n",
        "predict_single(input, target, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "xxOiGlsjC-mv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a02e863f-79b2-468a-aad7-3cbffb86e222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: tensor([60.0000,  0.0000, 28.6824,  0.0000,  0.0000])\n",
            "Target: tensor([28344.6738])\n",
            "Prediction: tensor([11637.3145])\n"
          ]
        }
      ],
      "source": [
        "input, target = val_ds[23]\n",
        "predict_single(input, target, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7Fm8gv4C-mv"
      },
      "source": [
        "Are you happy with your model's predictions? Try to improve them further."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}